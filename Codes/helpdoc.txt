Source Codes:
_____________

Experiment 1: SLR_Replication
-----------------------------
1. Search_SLR_Snowballing.py - it is the driver code for Snowballing experiment. The functions defined in extract_bib.py 
   and extract_cits.py files are imported and used here. It performs extraction of bibtex using their dois from a links.txt 
   file provided by the user. The extraction is done for the seed set of papers, and backward snowballing papers(references)
   and/or forward snowballing papers(citations) for a user specified number of iterations. The status of extraction of each 
   paper is stored in a common .csv file.

2. extract_bib.py - The bibtex of the papers using their dois is extracted here. The abstract of the papers are extracted 
   from ResearchGate. The bibtex of all the papers are saved in a common .bib file.

3. extract_cits.py - Here different helper functions are defined, for extracting dois of papers not returned by Semantic 
   Scholar, querying Semantic Scholar for papers, searching paper citations and handling a large number of queries to 
   Crossref for querying for dois using paper references, and constructing the reference string of a paper.

____________________________________________________________________________________________________________________________


Experiment 2: SLR_Update_Evaluation
-----------------------------------
1. create_dataset.py - extracts the Title and Abstract from the bibtex files 'Training-Included.bib' etc. and marks
   the relevance of the paper as 0 or 1 based on the label 'included' or 'excluded' in the file name. The output files
   generated by this are Training.csv and Testing.csv. These bibtex files were shared by an author of another paper.

2. Search_SLR_Update.ipynb - it performs dataframe manipulation of the Training and Testing-test csv files, then text pre-
   processing, and finally experiments the following ML algorithms: XGBoost, SGD, Logistic Regression, Multinomial Naive
   Bayes . The best model is SGD, and following it is XGBoost.
