@article{1027796,
 abstract = {Empirical software engineering research needs research guidelines to improve the research and reporting processes. We propose a preliminary set of research guidelines aimed at stimulating discussion among software researchers. They are based on a review of research guidelines developed for medical researchers and on our own experience in doing and reviewing software engineering research. The guidelines are intended to assist researchers, reviewers, and meta-analysts in designing, conducting, and evaluating empirical studies. Editorial boards of software engineering journals may wish to use our recommendations as a basis for developing guidelines for reviewers and for framing policies for dealing with the design, data collection, and analysis and reporting of empirical studies.},
 author = {Kitchenham, B.A. and Pfleeger, S.L. and Pickard, L.M. and Jones, P.W. and Hoaglin, D.C. and El Emam, K. and Rosenberg, J.},
 doi = {10.1109/TSE.2002.1027796},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {Aug},
 number = {8},
 pages = {721-734},
 title = {Preliminary guidelines for empirical research in software engineering},
 volume = {28},
 year = {2002}
}

@inproceedings{1183076,
 abstract = {Our activities in software engineering typically fall into one of three categories, (1) to invent new phenomena, (2) to understand existing phenomena, and (3) to facilitate inspirational education. This paper explores the place of empirical software engineering in the first two of these activities. In this exploration evidence is drawn from the empirical literature in the areas of software inspections and software cost modelling and estimation. This research is then compared with the literature published in the Journal of Empirical Software Engineering. This evidence throws light on aspects of theory derivation, experimental methods and analysis, and also the challenges that we face as empirical software engineering evolves into the future.},
 author = {Jeffery, R. and Scott, L.},
 booktitle = {Ninth Asia-Pacific Software Engineering Conference, 2002.},
 doi = {10.1109/APSEC.2002.1183076},
 issn = {1530-1362},
 keywords = {},
 month = {Dec},
 number = {},
 pages = {539-546},
 title = {Has twenty-five years of empirical software engineering made a difference?},
 volume = {},
 year = {2002}
}

@inproceedings{1317449,
 abstract = {Our objective is to describe how software engineering might benefit from an evidence-based approach and to identify the potential difficulties associated with the approach. We compared the organisation and technical infrastructure supporting evidence-based medicine (EBM) with the situation in software engineering. We considered the impact that factors peculiar to software engineering (i.e. the skill factor and the lifecycle factor) would have on our ability to practice evidence-based software engineering (EBSE). EBSE promises a number of benefits by encouraging integration of research results with a view to supporting the needs of many different stakeholder groups. However, we do not currently have the infrastructure needed for widespread adoption of EBSE. The skill factor means software engineering experiments are vulnerable to subject and experimenter bias. The lifecycle factor means it is difficult to determine how technologies will behave once deployed. Software engineering would benefit from adopting what it can of the evidence approach provided that it deals with the specific problems that arise from the nature of software engineering.},
 author = {Kitchenham, B.A. and Dyba, T. and Jorgensen, M.},
 booktitle = {Proceedings. 26th International Conference on Software Engineering},
 doi = {10.1109/ICSE.2004.1317449},
 issn = {0270-5257},
 keywords = {},
 month = {May},
 number = {},
 pages = {273-281},
 title = {Evidence-based software engineering},
 volume = {},
 year = {2004}
}

@inproceedings{1509301,
 abstract = {Many phenomena related to software development are qualitative in nature. Relevant measures of such phenomena are often collected using semi-structured interviews. Such interviews involve high costs, and the quality of the collected data is related to how the interviews are conducted. Careful planning and conducting of the interviews are therefore necessary, and experiences from interview studies in software engineering should consequently be collected and analyzed to provide advice to other researchers. We have brought together experiences from 12 software engineering studies, in which a total of 280 interviews were conducted. Four areas were particularly challenging when planning and conducting these interviews; estimating the necessary effort, ensuring that the interviewer had the needed skills, ensuring good interaction between interviewer and interviewees, and using the appropriate tools and project artifacts. The paper gives advice on how to handle these areas and suggests what information about the interviews should be included when reporting studies where interviews have been used in data collection. Knowledge from other disciplines is included. By sharing experience, knowledge about the accomplishments of software engineering interviews is increased and hence, measures of high quality can be achieved},
 author = {Hove, S.E. and Anda, B.},
 booktitle = {11th IEEE International Software Metrics Symposium (METRICS'05)},
 doi = {10.1109/METRICS.2005.24},
 issn = {1530-1435},
 keywords = {},
 month = {Sep.},
 number = {},
 pages = {10 pp.-23},
 title = {Experiences from conducting semi-structured interviews in empirical software engineering research},
 volume = {},
 year = {2005}
}

@article{1576650,
 abstract = {This article deals with Victor R. Basili's contributions to software quality. Basili's contributions cover three broad areas: research in the 1970s and early 1980s on software measurement and the Goal Question Metric (GQM) model, research in the 1980s and 1990s on these measurement ideas' maturation into a software engineering model of empirical studies, including the development of the Quality Improvement Paradigm (QIP) and the influence of the NASA Goddard Space Flight Center Software Engineering Laboratory, and research since 1990 in the Experience Factory as a model for creating learning organizations for continuous software process improvement. Some of Basili's most important contributions are in measuring software development processes and products and gifted the community with an invaluable tool: the GQM approach. The GQM approach is based on the assumption that for an organization to measure its products and processes usefully, it must first specify goals for itself and its projects},
 author = {Shull, F. and Seaman, C. and Zelkowltz, M.},
 doi = {10.1109/MS.2006.33},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Jan},
 number = {1},
 pages = {16-18},
 title = {Victor R. Basili's contributions to software quality},
 volume = {23},
 year = {2006}
}

@inproceedings{4221632,
 abstract = {We present the vision that for all fields of software engineering (SE), empirical research methods should enable the development of scientific knowledge about how useful different SE technologies are for different kinds of actors, performing different kinds of activities, on different kinds of systems. It is part of the vision that such scientific knowledge will guide the development of new SE technology and is a major input to important SE decisions in industry. Major challenges to the pursuit of this vision are: more SE research should be based on the use of empirical methods; the quality, including relevance, of the studies using such methods should be increased; there should be more and better synthesis of empirical evidence; and more theories should be built and tested. Means to meet these challenges include (1) increased competence regarding how to apply and combine alternative empirical methods, (2) tighter links between academia and industry, (3) the development of common research agendas with a focus on empirical methods, and (4) more resources for empirical research.},
 author = {Sjoberg, Dag I. K. and Dyba, Tore and Jorgensen, Magne},
 booktitle = {Future of Software Engineering (FOSE '07)},
 doi = {10.1109/FOSE.2007.30},
 issn = {},
 keywords = {},
 month = {May},
 number = {},
 pages = {358-378},
 title = {The Future of Empirical Methods in Software Engineering Research},
 volume = {},
 year = {2007}
}

@article{Carmel_2010,
 abstract = {Follow The Sun (FTS) has interesting appeal - hand-off work at the end of every day from one site to the next, many time zones away, in order to speed up product development. While the potential impact on "time-to-market" can be profound, at least conceptually, FTS has enjoyed very few documented industry successes because it is acknowledged to be extremely difficult to implement. In order to address this "FTS challenge" we provide here a conceptual foundation and formal definition of FTS. We then analyze the conditions under which FTS can be successful in reducing duration in software development. We show that handoff efficiency is paramount to successful FTS practices and that duration can be reduced only when lower within- site coordination and improved personal productivity outweigh the corresponding increase in cross-site coordination. We also develop 12 research propositions based on fundamental issues surrounding FTS, such as: calendar efficiency, development method, product architecture and hand-off efficiency, within-site coordination, cross-site coordination, and personal productivity. We combine the conceptual analysis with a description of our FTS exploratory comparative field studies and draw out their key findings and learning. The main implication of this article is that understanding calendar efficiency, hand-off efficiency, within-site coordination and cross-site coordination is necessary to evaluation - if FTS is to be successful in reducing software development duration.},
 author = {Erran Carmel and J. Alberto Espinosa and Yael Dubinsky},
 doi = {10.2753/mis0742-1222270102},
 journal = {Journal of Management Information Systems},
 month = {jul},
 number = {1},
 pages = {17--38},
 publisher = {Informa {UK} Limited},
 title = {"Follow the Sun" Workflow in Global Software Development},
 url = {https://doi.org/10.2753%2Fmis0742-1222270102},
 volume = {27},
 year = {2010}
}

@incollection{Ciolkowski_2003,
 abstract = {A survey is an empirical research strategy for the collection of information from heterogeneous sources. In this way, survey results often exhibit a high degree of external validity. It is complementary to other empirical research strategies such as controlled experiments, which usually have their strengths in the high internal validity of the findings. While there is a growing number of (quasi-)controlled experiments reported in the software engineering literature, few results of large scale surveys have been reported there. Hence, there is still a lack of knowledge on how to use surveys in a systematic manner for software engineering empirical research.
This chapter introduces a process for preparing, conducting, and analyzing a software engineering survey. The focus of the work is on questionnaire-based surveys rather than literature surveys. The survey process is driven by practical experiences from two large-scale efforts in the review and inspection area. There are two main results from this work. First, the process itself allows researchers in empirical software engineering to follow a systematic, disciplined approach. Second, the experiences from applying the process help avoid common pitfalls that endanger both the research process and its results. We report on two (descriptive) surveys on software reviews that applied the survey process, and we present our experiences, as well as models for survey effort and duration factors derived from these experiences.},
 author = {Marcus Ciolkowski and Oliver Laitenberger and Sira Vegas and Stefan Biffl},
 booktitle = {Empirical Methods and Studies in Software Engineering},
 doi = {10.1007/978-3-540-45143-3_7},
 pages = {104--128},
 publisher = {Springer Berlin Heidelberg},
 title = {Practical Experiences in the Design and Conduct of Surveys in Empirical Software Engineering},
 url = {https://doi.org/10.1007%2F978-3-540-45143-3_7},
 year = {2003}
}

@article{Falessi_2009,
 abstract = {In the last 15years, software architecture has emerged as an important software engineering field for managing the development
and maintenance of large, software-intensive systems. Software architecture community has developed numerous methods, techniques,
and tools to support the architecture process (analysis, design, and review). Historically, most advances in software architecture
have been driven by talented people and industrial experience, but there is now a growing need to systematically gather empirical
evidence about the advantages or otherwise of tools and methods rather than just rely on promotional anecdotes or rhetoric.
The aim of this paper is to promote and facilitate the application of the empirical paradigm to software architecture. To
this end, we describe the challenges and lessons learned when assessing software architecture research that used controlled
experiments, replications, expert opinion, systematic literature reviews, observational studies, and surveys. Our research
will support the emergence of a body of knowledge consisting of the more widely-accepted and well-formed software architecture
theories.

KeywordsSoftware architecture-Empirical software engineering},
 author = {Davide Falessi and Muhammad Ali Babar and Giovanni Cantone and Philippe Kruchten},
 doi = {10.1007/s10664-009-9121-0},
 journal = {Empirical Software Engineering},
 month = {dec},
 number = {3},
 pages = {250--276},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Applying empirical software engineering to software architecture: challenges and lessons learned},
 url = {https://doi.org/10.1007%2Fs10664-009-9121-0},
 volume = {15},
 year = {2009}
}

@article{Gupta_2011,
 abstract = {The 24- Hour Knowledge Factory is a paradigm in which globally distributed teams work on the same software development task in a sequential manner. It provides a service-oriented architecture model that facilitates round-the-clock operations through the deployment of multiple development teams around the globe. Complex projects are iteratively broken down into simpler modules, with a "composite persona" (CP) being responsible for each such module. In this paper, we delineate the key challenges that are encountered in the establishment of 24-hours knowledge factories. We present potential solutions to these problems and describe how some of these solutions have been validated with concept demonstration prototype systems.},
 author = {Amar Gupta and Nathan T. Denny and Kate O{\textquotesingle}Toole and Rajdeep Bondade and Damayanti Halder},
 doi = {10.1504/ijcat.2011.039140},
 journal = {International Journal of Computer Applications in Technology},
 number = {3},
 pages = {191},
 publisher = {Inderscience Publishers},
 title = {Global software development using the 24-Hour Knowledge Factory paradigm},
 url = {https://doi.org/10.1504%2Fijcat.2011.039140},
 volume = {40},
 year = {2011}
}

@article{Jarvenpaa_1988,
 abstract = {This preliminary study was conducted to learn about the consequences of computer support for teams working on unstructured, high-level conceptual software design problems in face-to-face group settings. A networked workstation technology and electronic blackboard technology were contrasted with their conventional counterparts. Twenty-one software designers, assigned to three teams, performed team tasks that involved generating ideas and reaching consensus. Positive effects on the thoroughness of information exchange and quality of team performance were found in the meetings in which electronic blackboard technology was available. The networked workstations provided mixed results. Significant team differences were found in performance and interaction measures. The results and their implications are discussed in terms of the necessary future developments and nature of future research in computer-based meeting support technology.},
 author = {Sirkka L. Jarvenpaa and V. Srinivasan Rao and George P. Huber},
 doi = {10.2307/249137},
 journal = {{MIS} Quarterly},
 month = {dec},
 number = {4},
 pages = {645},
 publisher = {{JSTOR}},
 title = {Computer Support for Meetings of Groups Working on Unstructured Problems: A Field Experiment},
 url = {https://doi.org/10.2307%2F249137},
 volume = {12},
 year = {1988}
}

@book{Juristo_2001,
 abstract = {Basics of Software Engineering Experimentation is a practical guide to experimentation in a field which has long been underpinned by suppositions, assumptions, speculations and beliefs. It demonstrates to software engineers how Experimental Design and Analysis can be used to validate their beliefs and ideas. The book does not assume its readers have an in-depth knowledge of mathematics, specifying the conceptual essence of the techniques to use in the design and analysis of experiments and keeping the mathematical calculations clear and simple. Basics of Software Engineering Experimentation is practically oriented and is specially written for software engineers, all the examples being based on real and fictitious software engineering experiments.},
 author = {Natalia Juristo and Ana M. Moreno},
 doi = {10.1007/978-1-4757-3304-4},
 publisher = {Springer {US}},
 title = {Basics of Software Engineering Experimentation},
 url = {https://doi.org/10.1007%2F978-1-4757-3304-4},
 year = {2001}
}

@article{Kitchenham_2002,
 abstract = {This second article of our series looks at the process of designing a survey. The design process begins with reviewing the objectives, examining the target population identified by the objectives, and deciding how best to obtain the information needed to address those objectives. However, we also need to consider factors such as determining the appropriate sample size and ensuring the largest possible response rate.To illustrate our ideas, we use the three surveys described in Part 1 of this series to suggest good and bad practice in software engineering survey research.},
 author = {Barbara A. Kitchenham and Shari Lawrence Pfleeger},
 doi = {10.1145/566493.566495},
 journal = {{ACM} {SIGSOFT} Software Engineering Notes},
 month = {jan},
 number = {1},
 pages = {18--20},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Principles of survey research part 2},
 url = {https://doi.org/10.1145%2F566493.566495},
 volume = {27},
 year = {2002}
}

@article{Lethbridge_2005,
 abstract = {Software engineering is an intensely people-oriented activity, yet too little is known about how designers, maintainers, requirements analysts and all other types of software engineers perform their work. In order to improve software engineering tools and practice, it is therefore essential to conduct field studies, i.e., to study real practitioners as they solve real problems. To do so effectively, however, requires an understanding of the techniques most suited to each type of field study task. In this paper, we provide a taxonomy of techniques, focusing on those for data collection. The taxonomy is organized according to the degree of human intervention each requires. For each technique, we provide examples from the literature, an analysis of some of its ad- vantages and disadvantages, and a discussion of how to use it effectively. We also briefly talk about field study design in general, and data analysis.},
 author = {Timothy C. Lethbridge and Susan Elliott Sim and Janice Singer},
 doi = {10.1007/s10664-005-1290-x},
 journal = {Empirical Software Engineering},
 month = {jul},
 number = {3},
 pages = {311--341},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Studying Software Engineers: Data Collection Techniques for Software Field Studies},
 url = {https://doi.org/10.1007%2Fs10664-005-1290-x},
 volume = {10},
 year = {2005}
}

@inproceedings{Perry_2000,
 abstract = {In this article we summarize the strengths and weaknesses of empirical research in software engineering. We argue that in order to improve the current situation we must create better studies and draw more credible interpretations from them. We finally present a roadmap for this improvement, which includes a general structure for software empirical studies and concrete steps for achieving these goals: designing better studies, collecting data more effectively, and involving others in our empirical enterprises. Keywords Empirical Studies, Software Engineering 1 INTRODUCTION An empirical study is really just a test that compares what we believe to what we observe. Nevertheless, such tests, when wisely constructed and executed and when used to support the scientific method, play a fundamental role in modern science. Specifically, they help us understand how and why things work, and allow us to use this understanding to materially alter our world. Yet in software engineering research, ...},
 author = {Dewayne E. Perry and Adam A. Porter and Lawrence G. Votta},
 booktitle = {Proceedings of the Conference on The Future of Software Engineering},
 doi = {10.1145/336512.336586},
 month = {may},
 publisher = {{ACM}},
 title = {Empirical studies of software engineering},
 url = {https://doi.org/10.1145%2F336512.336586},
 year = {2000}
}

@article{Rand_1983,
 abstract = {},
 author = {Graham K. Rand},
 doi = {10.1057/jors.1983.225},
 journal = {Journal of the Operational Research Society},
 month = {oct},
 number = {10},
 pages = {1020--1020},
 publisher = {Informa {UK} Limited},
 title = {Quantitative Applications in the Social Sciences},
 url = {https://doi.org/10.1057%2Fjors.1983.225},
 volume = {34},
 year = {1983}
}

@article{Vegas_2005,
 abstract = {One of the major problems within the software testing area is how to get a suitable set of cases to test a software system. This set should assure maximum effectiveness with the least possible number of test cases. There are now numerous testing techniques available for generating test cases. However, many are never used, and just a few are used over and over again. Testers have little (if any) information about the available techniques, their usefulness and, generally, how suited they are to the project at hand upon, which to base their decision on which testing techniques to use. This paper presents the results of developing and evaluating an artefact (specifically, a characterization schema) to assist with testing technique selection. When instantiated for a variety of techniques, the schema provides developers with a catalogue containing enough information for them to select the best suited techniques for a given project. This assures that the decisions they make are based on objective knowledge of the techniques rather than perceptions, suppositions and assumptions.},
 author = {Sira Vegas and Victor Basili},
 doi = {10.1007/s10664-005-3862-1},
 journal = {Empirical Software Engineering},
 month = {oct},
 number = {4},
 pages = {437--466},
 publisher = {Springer Science and Business Media {LLC}},
 title = {A Characterisation Schema for Software Testing Techniques},
 url = {https://doi.org/10.1007%2Fs10664-005-3862-1},
 volume = {10},
 year = {2005}
}

@article{Waxman_2006,
 abstract = {},
 author = {Lisa Waxman},
 doi = {10.1111/j.1939-1668.2006.tb00530.x},
 journal = {Journal of Interior Design},
 month = {may},
 number = {3},
 pages = {35--53},
 publisher = {{SAGE} Publications},
 title = {The Coffee Shop: Social and Physical factors Influencing Place Attachment},
 url = {https://doi.org/10.1111%2Fj.1939-1668.2006.tb00530.x},
 volume = {31},
 year = {2006}
}

@book{Wohlin_2000,
 abstract = {},
 author = {Claes Wohlin and Per Runeson and Martin Höst and Magnus C. Ohlsson and Björn Regnell and Anders Wessl{\'{e}}n},
 doi = {10.1007/978-1-4615-4625-2},
 publisher = {Springer {US}},
 title = {Experimentation in Software Engineering},
 url = {https://doi.org/10.1007%2F978-1-4615-4625-2},
 year = {2000}
}

@inproceedings{Zannier_2006,
 abstract = {},
 author = {Carmen Zannier and Grigori Melnik and Frank Maurer},
 booktitle = {Proceedings of the 28th international conference on Software engineering},
 doi = {10.1145/1134285.1134333},
 month = {may},
 publisher = {{ACM}},
 title = {On the success of empirical studies in the international conference on software engineering},
 url = {https://doi.org/10.1145%2F1134285.1134333},
 year = {2006}
}

@inproceedings{6223010,
 abstract = {Documentation plays a significant role in software development in general and in software architecture in particular. In large and complex systems, many changes affecting architecture and architectural documentation occur. This derives the need for constant changes within architecture documents in order to keep them up to date. This research in-progress aims to understand the current state of architecture maintenance towards proposing a solution for improving this practice via a well-defined process and supporting tools.},
 author = {Sherman, Sofia and Hadar, Irit},
 booktitle = {2012 5th International Workshop on Co-operative and Human Aspects of Software Engineering (CHASE)},
 doi = {10.1109/CHASE.2012.6223010},
 issn = {},
 keywords = {},
 month = {June},
 number = {},
 pages = {132-134},
 title = {Identifying the need for a sustainable architecture maintenance process},
 volume = {},
 year = {2012}
}

@article{Etzkowitz_1998,
 abstract = {We introduce a new hybrid approach to joint estimation of Value at Risk (VaR) and Expected Shortfall (ES) for high quantiles of return distributions. We investigate the relative performance of VaR and ES models using daily returns for sixteen stock market indices (eight from developed and eight from emerging markets) prior to and during the 2008 financial crisis. In addition to widely used VaR and ES models, we also study the behavior of conditional and unconditional extreme value (EV) models to generate 99 percent confidence level estimates as well as developing a new loss function that relates tail losses to ES forecasts. Backtesting results show that only our proposed new hybrid and Extreme Value (EV)-based VaR models provide adequate protection in both developed and emerging markets, but that the hybrid approach does this at a significantly lower cost in capital reserves. In ES estimation the hybrid model yields the smallest error statistics surpassing even the EV models, especially in the developed markets.},
 author = {Henry Etzkowitz},
 doi = {10.1016/s0048-7333(98)00093-6},
 journal = {Research Policy},
 month = {dec},
 number = {8},
 pages = {823--833},
 publisher = {Elsevier {BV}},
 title = {The norms of entrepreneurial science: cognitive effects of the new university{\textendash}industry linkages},
 url = {https://doi.org/10.1016%2Fs0048-7333%2898%2900093-6},
 volume = {27},
 year = {1998}
}

@article{Geuna_2001,
 abstract = {},
 author = {Aldo Geuna},
 doi = {10.1080/00213624.2001.11506393},
 journal = {Journal of Economic Issues},
 month = {sep},
 number = {3},
 pages = {607--632},
 publisher = {Informa {UK} Limited},
 title = {The Changing Rationale for European University Research Funding: Are There Negative Unintended Consequences?},
 url = {https://doi.org/10.1080%2F00213624.2001.11506393},
 volume = {35},
 year = {2001}
}

@article{Glaser_1968,
 abstract = {Most writing on sociological method has been concerned with how accurate facts can be obtained and how theory can thereby be more rigorously tested. In The Discovery of Grounded Theory, Barney Glaser and Anselm Strauss address the equally Important enterprise of how the discovery of theory from data--systematically obtained and analyzed in social research--can be furthered. The discovery of theory from data--grounded theory--is a major task confronting sociology, for such a theory fits empirical situations, and is understandable to sociologists and laymen alike. Most important, it provides relevant predictions, explanations, interpretations, and applications. In Part I of the book, "Generation Theory by Comparative Analysis," the authors present a strategy whereby sociologists can facilitate the discovery of grounded theory, both substantive and formal. This strategy involves the systematic choice and study of several comparison groups. In Part II, The Flexible Use of Data," the generation of theory from qualitative, especially documentary, and quantitative data Is considered. In Part III, "Implications of Grounded Theory," Glaser and Strauss examine the credibility of grounded theory. The Discovery of Grounded Theory is directed toward improving social scientists' capacity for generating theory that will be relevant to their research. While aimed primarily at sociologists, it will be useful to anyone Interested In studying social phenomena--political, educational, economic, industrial-- especially If their studies are based on qualitative data.},
 author = {Barney G. Glaser and Anselm L. Strauss and Elizabeth Strutzel},
 doi = {10.1097/00006199-196807000-00014},
 journal = {Nursing Research},
 month = {jul},
 number = {4},
 pages = {364},
 publisher = {Ovid Technologies (Wolters Kluwer Health)},
 title = {The Discovery of Grounded Theory$\mathsemicolon$ Strategies for Qualitative Research},
 url = {https://doi.org/10.1097%2F00006199-196807000-00014},
 volume = {17},
 year = {1968}
}

@article{Grossman_2001,
 abstract = {Results are presented of a National Academy of Engineering consensus study that documents the contributions of academic research to the growth and competitiveness of five industries – aerospace; financial services; medical devices; network systems and communications; and transportation, distribution, and logistics services. Academic research has made substantial contributions in varying degrees to all five industries. These have ranged from graduates trained in modern research techniques, to fundamental concepts and “key ideas” out of basic and applied research, to the development of tools, prototypes, and marketable products, processes, and services. In network systems, there is a history of university involvement in serving as test beds for new networking concepts and in spawning firms. The academic medical center provides a distinctive environment for testing and incremental improvement of medical devices and for conducting essential clinical trials. In financial services, academic economics and mathematics research contributions have been important, in spite of the lack of a well-developed R&D infrastructure for the industry. Challenges and opportunities for enhancing academic research contributions are presented in the areas of regulatory research and innovation, service sector innovation, information technology, intellectual property rights, and the role and identity of the university.},
 author = {Jerome H. Grossman and Proctor P. Reid and Robert P. Morgan},
 doi = {10.1023/a:1007848631448},
 journal = {The Journal of Technology Transfer},
 number = {1/2},
 pages = {143--152},
 publisher = {Springer Science and Business Media {LLC}},
 url = {https://doi.org/10.1023%2Fa%3A1007848631448},
 volume = {26},
 year = {2001}
}

@article{Hall_2001,
 abstract = {A small sample of 38 Advanced Technology Projects funded between 1993 and 1996 are surveyed to explore the reasons for university non-participation, or, in the cases where they did participate, whether the partnerships encountered any difficulties from their participation. 32 percent report that intellectual property issues were an insurmountable barrier to university participation. Such barriers are more likely when the ATP share of funding is high and when the expected duration of the research is relatively short. They are also somewhat more likely for projects involving chemical technology, and when industrial participants have had previous experience with universities as research partners. These difficulties over IP may arise because the cultures in the two institutional forms differ, or because the original ATP guidelines do not recognize the existence of the Bayh-Dole Act (which grants universities title to inventions made by their employees using outside funding).},
 author = {Bronwyn H. Hall and Albert N. Link and John T. Scott},
 doi = {10.1023/a:1007888312792},
 journal = {The Journal of Technology Transfer},
 number = {1/2},
 pages = {87--98},
 publisher = {Springer Science and Business Media {LLC}},
 url = {https://doi.org/10.1023%2Fa%3A1007888312792},
 volume = {26},
 year = {2001}
}

@article{Meyer_Krahmer_1998,
 abstract = {In recent years, the co-operation between industrial firms and universities has increased considerably, but the interaction pattern in different technological fields is not uniform. In science-based fields, university departments have a distinct focus on basic research and the major interest of industry is the observation of science. In less science-based fields, the solution of technical problems is a major concern of industry. In all fields, the exchange of knowledge in techno-scientific communities is a crucial element of interaction. In Germany, strong intra-disciplinary ties between universities and industry in mechanical engineering obviously imply an insufficient openness to, and integration of, new technologies. The particular combination of a long-standing culture of co-operation and the economic success in the mechanical industry can be interpreted in terms of a specific path-dependant evolution of a stable sector of the national system of innovation, but with the tendency to lock-in effects.},
 author = {Frieder Meyer-Krahmer and Ulrich Schmoch},
 doi = {10.1016/s0048-7333(98)00094-8},
 journal = {Research Policy},
 month = {dec},
 number = {8},
 pages = {835--851},
 publisher = {Elsevier {BV}},
 title = {Science-based technologies: university{\textendash}industry interactions in four fields},
 url = {https://doi.org/10.1016%2Fs0048-7333%2898%2900094-8},
 volume = {27},
 year = {1998}
}

@article{Perkmann_2009,
 abstract = {We analyze the impact of university--industry relationships on public research. Our inductive study of university--industry collaboration in engineering suggests that basic projects are more likely to yield academically valuable knowledge than applied projects. However, applied projects show higher degrees of partner interdependence and therefore enable exploratory learning by academics, leading to new ideas and projects. This result holds especially for research-oriented academics working in the "sciences of the artificial" and engaging in multiple relationships with industry. Our learning-centred interpretation qualifies the notion of entrepreneurial science as a driver of applied university--industry collaboration. We conclude with implications for science and technology policy. Copyright 2009 The Author 2009. Published by Oxford University Press on behalf of Associazione ICC. All rights reserved., Oxford University Press.},
 author = {M. Perkmann and K. Walsh},
 doi = {10.1093/icc/dtp015},
 journal = {Industrial and Corporate Change},
 month = {jun},
 number = {6},
 pages = {1033--1065},
 publisher = {Oxford University Press ({OUP})},
 title = {The two faces of collaboration: impacts of university-industry relations on public research},
 url = {https://doi.org/10.1093%2Ficc%2Fdtp015},
 volume = {18},
 year = {2009}
}

@article{Perkmann_2012,
 abstract = {A considerable body of work highlights the relevance of collaborative research, contract research, consulting and informal relationships for university-industry knowledge transfer. We present a systematic review of research on academic scientists’ involvement in these activities to which we refer as ‘academic engagement’. Apart from extracting findings that are generalisable across studies, we ask how academic engagement differs from commercialization, defined as intellectual property creation and academic entrepreneurship. We identify the individual, organizational and institutional antecedents and consequences of academic engagement, and then compare these findings with the antecedents and consequences of commercialization. Apart from being more widely practiced, academic engagement is distinct from commercialization in that it is closely aligned with traditional academic research activities, and pursued by academics to access resources supporting their research agendas. We conclude by identifying future research needs, opportunities for methodological improvement and policy interventions.},
 author = {Markus Perkmann and Valentina Tartari and Maureen McKelvey and Erkko Autio and Anders Brostrom and Pablo D{\textquotesingle}Este and Riccardo Fini and Aldo Geuna and Rosa Grimaldi and Alan Hughes and M. Kitson and Stefan Krabel and Patrick Llerena and Francesco Lissoni and Ammon Salter and Maurizio Sobrero},
 doi = {10.2139/ssrn.2088253},
 journal = {{SSRN} Electronic Journal},
 publisher = {Elsevier {BV}},
 title = {Academic Engagement and Commercialization: A Review of the Literature on University-Industry Relations},
 url = {https://doi.org/10.2139%2Fssrn.2088253},
 year = {2012}
}

@article{4012630,
 abstract = {Successful technology transfer requires close cooperation and collaboration between researchers and practitioners. Researchers need to observe the challenges facing industry firsthand and tailor their work accordingly. Practitioners can help shape technology development on the basis of tangible issues identified on site. This article presents a seven-step technology transfer model that reflects collaborations between university researchers and practitioners at two Swedish companies. The authors discuss key lessons learned for each of these seven steps.},
 author = {Gorschek, Tony and Garre, Per and Larsson, Stig and Wohlin, Claes},
 doi = {10.1109/MS.2006.147},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Nov},
 number = {6},
 pages = {88-95},
 title = {A Model for Technology Transfer in Practice},
 volume = {23},
 year = {2006}
}

@article{Barbolla_2009,
 abstract = {This study provides insight into the reality of university-industry technology transfer through the assessment of some of the most influential factors for success or failure in research contracts. This widespread mechanism of technology transfer is examined in the light of exhaustive information and experience gathered from 30 interviews with qualified university researchers. The interviewees, who have been directly involved in collaborative projects with industry partners, have deeply described both sound and unsatisfactory cooperation cases, in order to explore which relevant circumstances have led to success or failure. The analysis drives to conclude that there are some features (beyond technological ones) related to the corporate partner's strategic and functional characteristics, which come to be decisive for success. For example, company's real interest and involvement during the technology transfer process, its capacity to assimilate new knowledge and a confident attitude towards the university research group are identified to be key elements for attaining an effective technology transfer. In this contribution, the importance of these aspects is contextualised and summarised in a model for successful technology transfer.},
 author = {Ana M. Bernardos Barbolla and Jos{\'{e}} R. Casar Corredera},
 doi = {10.1080/09537320902969133},
 journal = {Technology Analysis {\&}amp$\mathsemicolon$ Strategic Management},
 month = {jul},
 number = {5},
 pages = {599--616},
 publisher = {Informa {UK} Limited},
 title = {Critical factors for success in university{\textendash}industry research projects},
 url = {https://doi.org/10.1080%2F09537320902969133},
 volume = {21},
 year = {2009}
}

@article{Barnes_2002,
 abstract = {There is a growing world-wide trend toward greater collaboration between academia and industry, an activity encouraged by governments as a means of enhancing national competitiveness and wealth creation. Warwick Manufacturing Group (WMG) is well known for its extensive links with industry, and provided an excellent opportunity for a study of management practice within university–industry collaborative research projects. This paper evaluates the findings of six collaborative research projects. The objective was to identify factors which, if managed correctly, increase the probability of a collaboration being perceived as successful by both academic and industrial partners. The outcome was a good practice model for successful university–industry research collaborations.},
 author = {Tina Barnes and Ian Pashby and Anne Gibbons},
 doi = {10.1016/s0263-2373(02)00044-0},
 journal = {European Management Journal},
 month = {jun},
 number = {3},
 pages = {272--285},
 publisher = {Elsevier {BV}},
 title = {Effective University {\textendash} Industry Interaction:},
 url = {https://doi.org/10.1016%2Fs0263-2373%2802%2900044-0},
 volume = {20},
 year = {2002}
}

@article{David_1960,
 abstract = {},
 author = {F. N. David and Gunnar Blom},
 doi = {10.2307/2332984},
 journal = {Biometrika},
 month = {jun},
 number = {1/2},
 pages = {210},
 publisher = {{JSTOR}},
 title = {Statistical Estimates and Transformed Beta-Variables.},
 url = {https://doi.org/10.2307%2F2332984},
 volume = {47},
 year = {1960}
}

@article{1159025,
 abstract = {In the automotive industry, especially in the high-end market, the complexity of electronic components is increasing rapidly. Currently, about a third of all development costs in high-end models go to electric and electronic system development, and the cost continues to grow. At the same time, many slightly different variations on components are each developed in a series of prototyping phases on different schedules. Consequently, the complexity of specification activities surpasses what conventional text-processing systems can support in terms of management and tracing functionality. Using real world projects as a foundation, the authors describe problems and solutions for requirements engineering in the automotive domain.},
 author = {Weber, M. and Weisbrod, J.},
 doi = {10.1109/MS.2003.1159025},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Jan},
 number = {1},
 pages = {16-24},
 title = {Requirements engineering in automotive development: experiences and challenges},
 volume = {20},
 year = {2003}
}

@article{819965,
 abstract = {We can learn much from the business community about effective technology transfer. In particular, understanding the interests of different types of adopters can suggest to us the different kinds of evidence needed to convince someone to try an innovative technology. At the same time, the legal community offers us advice about what kinds of evidence are needed to build convincing cases that an innovation is an improvement over current practice. The article examines why and how we make technology selection decisions and also considers how evidence supporting these decisions helps or hinders the adoption of new technology.},
 author = {Pfleeger, S.L. and Menezes, W.},
 doi = {10.1109/52.819965},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Jan},
 number = {1},
 pages = {27-33},
 title = {Marketing technology to software practitioners},
 volume = {17},
 year = {2000}
}

@inproceedings{Basili_2002,
 abstract = {For 25 years the NASA/GSFC Software Engineering Laboratory (SEL) has been a major resource in software process improvement activities. But due to a changing climate at NASA, agency reorganization, and budget cuts, the SEL has lost much of its impact. In this paper we describe the history of the SEL and give some lessons learned on what we did right, what we did wrong, and what others can learn from our experiences. We briefly describe the research that was conducted by the SEL, describe how we evolved our understanding of software process improvement, and provide a set of lessons learned and hypotheses that should enable future groups to learn from and improve on our quarter century of experiences.},
 author = {Victor R. Basili and Frank E. McGarry and Rose Pajerski and Marvin V. Zelkowitz},
 booktitle = {Proceedings of the 24th international conference on Software engineering  - {ICSE} {\textquotesingle}02},
 doi = {10.1145/581339.581351},
 publisher = {{ACM} Press},
 title = {Lessons learned from 25 years of process improvement},
 url = {https://doi.org/10.1145%2F581339.581351},
 year = {2002}
}

@article{Gorschek_2004,
 abstract = {Software process improvement is a challenge in general and in particular for small- and medium-sized companies. Assessment is one important step in improvement. However, given that a list of improvement issues has been derived, it is often very important to be able to prioritize the improvement proposals and also look at the potential dependencies between them. This paper comes from an industrial need to enable prioritization of improvement proposals and to identify their dependencies. The need was identified in a small- and medium-sized software development company. Based on the need, a method for prioritization and identification of dependencies of improvement proposals was developed. The prioritization part of the method is based on a multi-decision criteria method and the dependencies are identified using a dependency graph. The developed method has been successfully applied in the company, where people with different roles applied the method. The paper presents both the method as such and the successful application of it. It is concluded that the method worked as a means for prioritization and identification of dependencies. Moreover, the method also allowed the employees to discuss and reason about the improvement actions to be taken in a structured and systematic way. Copyright © 2004 John Wiley & Sons, Ltd.},
 author = {Tony Gorschek and Claes Wohlin},
 doi = {10.1002/spe.615},
 journal = {Software: Practice and Experience},
 number = {14},
 pages = {1311--1344},
 publisher = {Wiley},
 title = {Packaging software process improvement issues: a method and a case study},
 url = {https://doi.org/10.1002%2Fspe.615},
 volume = {34},
 year = {2004}
}

@article{Gorschek_2005,
 abstract = {Software requirements arrive in different shapes and forms to development organizations. This is particularly the case in
market-driven requirements engineering, where the requirements are on products rather than directed towards projects. This
results in challenges related to making different requirements comparable. In particular, this situation was identified in
a collaborative effort between academia and industry. A model, with four abstraction levels, was developed as a response to
the industrial need. The model allows for placement of requirements on different levels and supports abstraction or break
down of requirements to make them comparable to each other. The model was successfully validated in several steps at a company.
The results from the industrial validation point to the usefulness of the model. The model will allow companies to ensure
comparability between requirements, and hence it generates important input to activities such as prioritization and packaging
of requirements before launching a development project.},
 author = {Tony Gorschek and Claes Wohlin},
 doi = {10.1007/s00766-005-0020-7},
 journal = {Requirements Engineering},
 month = {nov},
 number = {1},
 pages = {79--101},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Requirements Abstraction Model},
 url = {https://doi.org/10.1007%2Fs00766-005-0020-7},
 volume = {11},
 year = {2005}
}

@article{Kaindl_2002,
 abstract = {For many years, research results in requirements engineering (RE) have been developed without much interaction with, or impact on, industrial practice. Why is it so difficult to introduce RE research results into mainstream RE practice? This paper attempts to provide answers to this question by describing obstacles that researchers and practitioners have encountered when they attempted technology transfer. In addition, major incentives for using RE methods are discussed, along with ideas for improving current RE practice. The paper summarises, clarifies and extends the results of two panel discussions, one at the Twelfth Conference on Advanced information Systems Engineering (CAiSE'00) and the other at the Fourth IEEE Conference on Requirements Engineering (ICRE'00).},
 author = {Hermann Kaindl and Sjaak Brinkkemper and Janis A. Bubenko Jr and Barbara Farbey and Sol J. Greenspan and Constance L. Heitmeyer{\ast} and Julio Cesar Sampaio do Prado Leite{\textdagger} and Nancy R. Mead and John Mylopoulos and Jawed Siddiqi},
 doi = {10.1007/s007660200008},
 journal = {Requirements Engineering},
 month = {sep},
 number = {3},
 pages = {113--123},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Requirements Engineering and Technology Transfer: Obstacles, Incentives and Improvement Agenda},
 url = {https://doi.org/10.1007%2Fs007660200008},
 volume = {7},
 year = {2002}
}

@article{Morris_1998,
 abstract = {In September 1996 the Joint Research Centre of the European Commission held a workshop in Brussels on problems with industrial uptake from research and development projects in Requirements Engineering. Although there have, in this domain, been a number of research projects industrial uptake has rarely lived up to expectations. The workshop set out to investigate possible explanations for this and what potential mechanisms there may be for promoting industrial uptake of current and future Requirement Engineering projects. This paper has two functions: to describe the results of this workshops and to provide a framework to support planning for future RE activities and initiatives.},
 author = {Philip Morris and Marcelo Masera and Marc Wilikens},
 doi = {10.1007/bf02919966},
 journal = {Requirements Engineering},
 month = {jun},
 number = {2},
 pages = {79--83},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Requirements engineering and industrial uptake},
 url = {https://doi.org/10.1007%2Fbf02919966},
 volume = {3},
 year = {1998}
}

@article{Pfleeger_1999,
 abstract = {Technology transfer in software engineering involves more than a new idea or evidence that it works. This paper illustrates how technology transfer requires a good idea, the generation of evidence, analysis of that evidence, good packaging and support, and careful consideration of the audience for the technology. By learning from other disciplines, we present a model of technology transfer that can be tailored to a particular organisation's needs.},
 author = {S.L Pfleeger},
 doi = {10.1016/s0164-1212(99)00031-x},
 journal = {Journal of Systems and Software},
 month = {jul},
 number = {2-3},
 pages = {111--124},
 publisher = {Elsevier {BV}},
 title = {Understanding and improving technology transfer in software engineering},
 url = {https://doi.org/10.1016%2Fs0164-1212%2899%2900031-x},
 volume = {47},
 year = {1999}
}

@inproceedings{183700,
 abstract = {Three underlying models of technology transfer emerged from an analysis of interviews with 55 aerospace managers using a dialectic method. One called for the transfer of experts, another for better communication, and the third required the technologies be on the shelf. The models were based on conflicting assumptions and were self-contradictory when pushed to an extreme. Together, they encompassed critical issues of technology transfer. A composite team organization was proposed which successfully met project, R&D, and technology transfer requirements.<>},
 author = {Berniker, E.},
 booktitle = {Technology Management : the New International Language},
 doi = {10.1109/PICMET.1991.183700},
 issn = {},
 keywords = {},
 month = {Oct},
 number = {},
 pages = {499-502},
 title = {Models of technology transfer. (A dialectical case study)},
 volume = {},
 year = {1991}
}

@article{363160,
 abstract = {Hewlett-Packard have investigated how to improve software development using systematic software reuse. The author discusses what Hewlett-Packard has learned about software reuse. The article explains what software reuse can and cannot deliver.<>},
 author = {Griss, M.L. and Wosser, M.},
 doi = {10.1109/52.363160},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Jan},
 number = {1},
 pages = {105-107},
 title = {Making reuse work at Hewlett-Packard},
 volume = {12},
 year = {1995}
}

@article{566148,
 abstract = {Practitioners and researchers continue to seek methods and tools for improving software development processes and products. Candidate technologies promise increased productivity, better quality, lower cost, or enhanced customer satisfaction. We must test these methods and tools empirically and rigorously to determine any significant, quantifiable improvement. We tend to consider evaluation only after using the technology, which makes careful, quantitative analysis difficult if not impossible. However, when an evaluation is designed as part of overall project planning, and then carried out as software development progresses, the result can be a rich record of a tool's or technique's effectiveness. In this study, we investigated the effects of using formal methods to develop an air-traffic-control information system.},
 author = {Pfleeger, S.L. and Hatton, L.},
 doi = {10.1109/2.566148},
 issn = {1558-0814},
 journal = {Computer},
 keywords = {},
 month = {Feb},
 number = {2},
 pages = {33-43},
 title = {Investigating the influence of formal methods},
 volume = {30},
 year = {1997}
}

@article{584923,
 abstract = {The increasing importance of emerging information technologies has prompted many researchers to examine the nature of innovation adoption within organizations. However, the nature of organizational influences in the innovation adoption process is still not well understood. This study surveyed Business Week 1000 companies to determine whether organizational strategies, structure, or context facilitate the adoption decision of integrated services digital networks (ISDN). The results suggest that companies most receptive to ISDN are larger, less open, have more slack resources, more technology expansion actions, and fewer technology restriction actions.},
 author = {Lai, V.S. and Guynes, J.L.},
 doi = {10.1109/17.584923},
 issn = {1558-0040},
 journal = {IEEE Transactions on Engineering Management},
 keywords = {},
 month = {May},
 number = {2},
 pages = {146-157},
 title = {An assessment of the influence of organizational characteristics on information technology adoption decision: a discriminative approach},
 volume = {44},
 year = {1997}
}

@article{FH_1995,
 abstract = {},
 author = {FH and David A. Schum},
 doi = {10.2307/2291371},
 journal = {Journal of the American Statistical Association},
 month = {sep},
 number = {431},
 pages = {1136},
 publisher = {{JSTOR}},
 title = {The Evidential Foundations of Probabilistic Reasoning.},
 url = {https://doi.org/10.2307%2F2291371},
 volume = {90},
 year = {1995}
}

@article{Fichman_1997,
 abstract = {The burden of organizational learning surrounding software process innovations (SPIs)---and complex organizational technologies in general---creates a "knowledge barrier" that inhibits diffusion. Attewell (Attewell, P. 1992. Technology diffusion and organizational learning the case of business computing. Organ. Sci. 3(1) 1--19.) has suggested that many organizations will defer adoption until knowledge barriers have been sufficiently lowered; however, this leaves open the question of which organizations should be more likely to innovate, even in face of high knowledge barriers. It is proposed here that organizations will innovate in the presence of knowledge barriers when the burden of organizational learning is effectively lower, either because much of the required know-how already exists within the organization, or because such knowledge can be acquired more easily or more economically. Specifically, it is hypothesized that organizations will have a greater propensity to initiate and sustain the assimilation of SPIs when they have a greater scale of activities over which learning costs can be spread (learning-related scale), more extensive existing knowledge related to the focal innovation (related knowledge), and a greater diversity of technical knowledge and activities (diversity). An empirical study using data on the assimilation of object-oriented programming languages (OOPLs) by 608 information technology organizations strongly confirmed the importance of the three hypothesized factors in explaining the assimilation of OOPLs.},
 author = {Robert G. Fichman and Chris F. Kemerer},
 doi = {10.1287/mnsc.43.10.1345},
 journal = {Management Science},
 month = {oct},
 number = {10},
 pages = {1345--1363},
 publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
 title = {The Assimilation of Software Process Innovations: An Organizational Learning Perspective},
 url = {https://doi.org/10.1287%2Fmnsc.43.10.1345},
 volume = {43},
 year = {1997}
}

@article{Premkumar_1995,
 abstract = {This study examines the impact of various organizational and technology characteristics on the adoption of computer aided software engineering (CASE) technology. Based on research in innovation adoption and IS implementation, the study develops a research model comprised of seven factors that are important for the successful adoption of CASE technology. The data for the study were collected through a field survey of IS managers in the midwest area and 90 responses were received. The results of discriminant analysis reveal that of the seven predictor variables, five are important to differentiate adopters from non-adopters. They are the existence of a product champion, strong top management support, lower IS expertise, perception that CASE technology has greater relative advantage over other alternatives, and a conviction of the cost effectiveness of the technology. The results are consistent with findings in innovation adoption literature as well as case studies of many firms' experience on CASE implementation.},
 author = {G. Premkumar and Michael Potter},
 doi = {10.1145/217278.217291},
 journal = {{ACM} {SIGMIS} Database: the {DATABASE} for Advances in Information Systems},
 month = {may},
 number = {2-3},
 pages = {105--124},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Adoption of computer aided software engineering ({CASE}) technology},
 url = {https://doi.org/10.1145%2F217278.217291},
 volume = {26},
 year = {1995}
}

@article{Prescott_1995,
 abstract = {Research based on diffusion of innovation (DOI) theory investigates the evaluation, adoption, and implementation of innovations. Gaining understanding is difficult when tracing results on a study-by-study basis. To remove some of the barriers to comparison of results, we distinguish between innovations according to their locus of impact (IS unit, intra- or inter-organizational) and between studies according to research approach (factor or stage).A representative sample of 70 information technology (IT) related DOI research studies published by IT researchers over the last decade is evaluated using this classification scheme. From the analysis, it appears that the classification scheme may be used to provide a clearer understanding of IT innovation diffusion.Traditional DOI theory appears to be most applicable to ITs which have an intra-organizational locus of impact. ITs with an information system (IS) unit locus of impact appear to require less organizational support, and their extent of implementation appears to be related to nontraditional innovation characteristics such as functionality and efficiency. Inter-organizational locus of impact IT innovations, however, appear to be more affected by contextual and environmental variables, and their differences may be better explained by economic influence or critical mass theories.},
 author = {Mary B. Prescott and Sue A. Conger},
 doi = {10.1145/217278.217284},
 journal = {{ACM} {SIGMIS} Database: the {DATABASE} for Advances in Information Systems},
 month = {may},
 number = {2-3},
 pages = {20--41},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Information technology innovations},
 url = {https://doi.org/10.1145%2F217278.217284},
 volume = {26},
 year = {1995}
}

@article{Rai_1995,
 abstract = {This paper examines the relationship between perceived ‘knowledge transfer’ effectiveness of different information channels for computer-aided software engineering (CASE) technology and CASE innovation diffusion. Specifically, the knowledge transfer effectiveness of seven information sources and channels is assessed. CASE innovation behaviour is modelled using three stages: initiation, adoption and implementation. Three types of CASE innovations are examined: two technical process innovations and one administrative innovation. Data for the empirical study were collected through a large-scale national survey of senior IS managers. A total of 405 usable responses were received. The perceived knowledge transfer effectiveness of the information sources and channels is associated differently with the initiation, adoption and implementation phases of the innovation process. Further, these associations are not uniform across the three categories of CASE innovations. The study has implications for how knowledge barriers can be alleviated during the CASE diffusion process.},
 author = {A Rai},
 doi = {10.1057/ejis.1995.11},
 journal = {European Journal of Information Systems},
 month = {may},
 number = {2},
 pages = {93--102},
 publisher = {Informa {UK} Limited},
 title = {External information source and channel effectiveness and the diffusion of {CASE} innovations: an empirical study},
 url = {https://doi.org/10.1057%2Fejis.1995.11},
 volume = {4},
 year = {1995}
}

@inproceedings{1237993,
 abstract = {In order to investigate practitioners' opinions of software process and software process improvement, we have collected a large volume of qualitative evidence from 13 companies. At the same time, other researchers have reported investigations of practitioners, and we are interested in how their reports may relate to our evidence. Thus, other research publications can also be treated as a form of qualitative data. In this paper, we review advice on a method, content analysis, which is used to analyse qualitative data. We use content analysis to describe and analyse discussions on software process and software process improvement. We report preliminary findings from an analysis of both the focus group evidence and four publications. Our main finding is that there is an apparent contradiction between developers saying that they want evidence for software process improvement, and what developers will accept as evidence. This presents a serious problem for research: even if researchers could demonstrate a strong, reliable relationship between software process improvement and improved organisational performance, there would still be the problem of convincing practitioners that the evidence applies to their particular situation.},
 author = {Rainer, A. and Hall, T. and Baddoo, N.},
 booktitle = {2003 International Symposium on Empirical Software Engineering, 2003. ISESE 2003. Proceedings.},
 doi = {10.1109/ISESE.2003.1237993},
 issn = {},
 keywords = {},
 month = {Sep.},
 number = {},
 pages = {326-335},
 title = {Persuading developers to "buy into" software process improvement: a local opinion and empirical evidence},
 volume = {},
 year = {2003}
}

@article{4012630,
 abstract = {Successful technology transfer requires close cooperation and collaboration between researchers and practitioners. Researchers need to observe the challenges facing industry firsthand and tailor their work accordingly. Practitioners can help shape technology development on the basis of tangible issues identified on site. This article presents a seven-step technology transfer model that reflects collaborations between university researchers and practitioners at two Swedish companies. The authors discuss key lessons learned for each of these seven steps.},
 author = {Gorschek, Tony and Garre, Per and Larsson, Stig and Wohlin, Claes},
 doi = {10.1109/MS.2006.147},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Nov},
 number = {6},
 pages = {88-95},
 title = {A Model for Technology Transfer in Practice},
 volume = {23},
 year = {2006}
}

@article{5733335,
 abstract = {Both the software industry and academia promote collaboration to solve challenges together that neither can solve alone. Collaboration brings opportunities to understand and improve in ways not possible when working apart, but it succeeds only if both parties are contributing. A collaboration model developed from eight years' experience setting up and managing a research center explicitly focused on industry needs is based on five success factors enabling research results (need orientation, industry goal alignment, deployment impact, industry benefit, and innovativeness), five success factors enabling research activities (management engagement, network access, collaborator match, communication ability, and continuity), and 10 action principles for industry-academia collaboration management.},
 author = {Sandberg, Anna and Pareto, Lars and Arts, Thomas},
 doi = {10.1109/MS.2011.49},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {July},
 number = {4},
 pages = {74-83},
 title = {Agile Collaborative Research: Action Principles for Industry-Academia Collaboration},
 volume = {28},
 year = {2011}
}

@inproceedings{5770626,
 abstract = {Background: History based regression testing was proposed as a basis for automating regression test selection, for the purpose of improving transparency and test efficiency, at the function test level in a large scale software development organization. Aim: The study aims at investigating the current manual regression testing process as well as adopting, implementing and evaluating the effect of the proposed method. Method: A case study was launched including: identification of important factors for prioritization and selection of test cases, implementation of the method, and a quantitative and qualitative evaluation. Results: 10 different factors, of which two are history-based, are identified as important for selection. Most of the information needed is available in the test management and error reporting systems while some is embedded in the process. Transparency is increased through a semi-automated method. Our quantitative evaluation indicates a possibility to improve efficiency, while the qualitative evaluation supports the general principles of history-based testing but suggests changes in implementation details.},
 author = {Engström, Emelie and Runeson, Per and Ljung, Andreas},
 booktitle = {2011 Fourth IEEE International Conference on Software Testing, Verification and Validation},
 doi = {10.1109/ICST.2011.27},
 issn = {2159-4848},
 keywords = {},
 month = {March},
 number = {},
 pages = {367-376},
 title = {Improving Regression Testing Transparency and Efficiency with History-Based Prioritization -- An Industrial Case Study},
 volume = {},
 year = {2011}
}

@article{Arif_2010,
 abstract = {The University of Salford, UK and Indian Green Building Council, Hyderabad, India, organized a workshop in Hyderabad on June 26, 2009 to examine the issue of industry academia collaboration to encourage green construction in India. Some of the major objectives of the workshop included identifying the key needs of the industry with regard to green construction in the country and identifying and discussing the key challenges associated with developing appropriate academic curriculum and improving the relationship with industry in green construction. The event was attended by 70 participants, including academic professionals and practitioners in the area of green buildings. The participants were provided with an overview of the objectives of the workshop in the first half and presented with the findings from the event, held in in New Delhi, India, in July of 2008.},
 author = {Mohammed Arif and Charles Egbu and Mustafa Alshawi and S. Srinivas and Mohammad Tariq},
 doi = {10.1061/(asce)ei.1943-5541.0000019},
 journal = {Journal of Professional Issues in Engineering Education and Practice},
 month = {jul},
 number = {3},
 pages = {128--131},
 publisher = {American Society of Civil Engineers ({ASCE})},
 title = {Promoting Green Construction in India through Industry-Academia Collaboration},
 url = {https://doi.org/10.1061%2F%28asce%29ei.1943-5541.0000019},
 volume = {136},
 year = {2010}
}

@article{Bjerregaard_2010,
 abstract = {Research on university–industry (UI) collaboration has addressed how cultural differences between firms and universities tend to impede knowledge exchange and impose challenges on project control if not properly addressed. Relatively little research has examined in-depth how changing institutional logics of R&D practice shape concrete UI collaborations at the micro-level of interacting researchers. The purpose of this study is to examine how conflicting and converging institutional logics of R&D work enable and constrain the process of R&D collaboration between small and medium sized enterprises (SMEs) and public university departments. This qualitative study covers the total population of public university departments and firms involved in collaborative research projects sponsored by a programme under the National Strategic Research Council (NSRC) in Denmark. The findings show that many of the collaborating researchers experienced an institutional convergence constituting a shared cultural space for knowledge exchange and communication in their joint projects. In some cases this lack of normative conflict was due to a blurring of institutional logics governing R&D in the two sectors. Furthermore, some researchers were able to use their social skills to bridge perceived institutional gaps. Implications for future research and UI collaboration are addressed.},
 author = {Toke Bjerregaard},
 doi = {10.1016/j.technovation.2009.11.002},
 journal = {Technovation},
 month = {feb},
 number = {2},
 pages = {100--108},
 publisher = {Elsevier {BV}},
 title = {Industry and academia in convergence: Micro-institutional dimensions of R{\&}amp$\mathsemicolon$D collaboration},
 url = {https://doi.org/10.1016%2Fj.technovation.2009.11.002},
 volume = {30},
 year = {2010}
}

@article{Mujumdar_2010,
 abstract = {},
 author = {Arun S. Mujumdar},
 doi = {10.1080/07373931003609427},
 journal = {Drying Technology},
 month = {mar},
 number = {4},
 pages = {431--432},
 publisher = {Informa {UK} Limited},
 title = {Editorial on Industry{\textendash}Academia Collaboration in R{\&}amp$\mathsemicolon$D},
 url = {https://doi.org/10.1080%2F07373931003609427},
 volume = {28},
 year = {2010}
}

@book{Runeson_2012,
 abstract = {Introduction Design of the Case Study Data Collection Data Analysis Reporting and Dissemination Lessons Learned},
 author = {Per Runeson and Martin Höst and Austen Rainer and Björn Regnell},
 doi = {10.1002/9781118181034},
 month = {feb},
 publisher = {Wiley},
 title = {Case Study Research in Software Engineering},
 url = {https://doi.org/10.1002%2F9781118181034},
 year = {2012}
}

@inproceedings{Yamada_2008,
 abstract = {Processes employing clusters of ions comprised of a few hundred to many thousand atoms are now being developed into a new field of ion beam technology. Cluster‐surface collisions produce important non‐linear effects which are being applied to shallow junction formation, to etching and smoothing of semiconductors, 
metals, and dielectrics, to assisted formation of thin films with nano‐scale accuracy, and to other surface modification applications. In 2000, a four year R&D project for development of industrial technology began in Japan under funding from the New Energy and Industrial Technology Development Organization (NEDO). Subjects of the projects are in areas of equipment development, semiconductor surface processing, high accuracy surface processing and high‐quality film formation. In 2002, another major cluster ion beam project which emphasized nano‐technology applications has started under a contract from the Ministry of Economy and Technology for Industry (METI). This METI project involved development related to size‐selected cluster ion beam equipment and processes, and development of GCIB processes for very high rate etching and for zero damage etching of magnetic materials and compound semiconductor materials. This paper describes summery of the results.},
 author = {Isao Yamada and Jiro Matsuo and Noriaki Toyoda and Edmund G. Seebauer and Susan B. Felch and Amitabh Jain and Yevgeniy V. Kondratenko},
 booktitle = {{AIP} Conference Proceedings},
 doi = {10.1063/1.3033651},
 publisher = {{AIP}},
 title = {Summary of Industry-Academia Collaboration Projects on Cluster Ion Beam Process Technology},
 url = {https://doi.org/10.1063%2F1.3033651},
 year = {2008}
}

@inproceedings{6200202,
 abstract = {Industry - academia collaboration is critical for empirical research to exist. However, there are many obstacles in the collaboration process. This paper reports on the experiences gained by the author, in a 2-year collaboration project on software testing which involved on-site work by the researcher in the industry premises. Based on notes, minutes of meetings, and progress reports, the project history is outlined. The project is analyzed, using collaboration models as a frame of reference. We conclude that there must be a balance between company 'pull' and academia 'push' in the collaboration Management support is inevitably a key factor to success, while other factors like cross-cultural skills and interfaces towards key resources also contribute.},
 author = {Runeson, Per},
 booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
 doi = {10.1109/ICST.2012.190},
 issn = {2159-4848},
 keywords = {},
 month = {April},
 number = {},
 pages = {872-877},
 title = {It Takes Two to Tango -- An Experience Report on Industry -- Academia Collaboration},
 volume = {},
 year = {2012}
}

@article{5963631,
 abstract = {Collaboration between industry and academia supports improvement and innovation in industry and helps to ensure industrial relevance in academic research. This article presents an exploratory study of the factors for successful collaboration between industry and academia in software research.},
 author = {Wohlin, Claes and Aurum, Aybuke and Angelis, Lefteris and Phillips, Laura and Dittrich, Yvonne and Gorschek, Tony and Grahn, Hakan and Henningsson, Kennet and Kagstrom, Simon and Low, Graham and Rovegard, Per and Tomaszewski, Piotr and van Toorn, Christine and Winter, Jeff},
 doi = {10.1109/MS.2011.92},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {March},
 number = {2},
 pages = {67-73},
 title = {The Success Factors Powering Industry-Academia Collaboration},
 volume = {29},
 year = {2012}
}

@inproceedings{6337756,
 abstract = {Product line engineering is an approach that works well for managing the anticipated variability of software systems as demonstrated in numerous studies. However, little empirical research and few approaches exist for dealing with the unanticipated evolution of product lines. As a result, the understanding of product line evolution is still weak and the maturity of approaches and tools supporting evolution is often insufficient. In this paper we present results of a case study on impact analyses and desired tool support in product line evolution. Our findings are based on observing 30 person months of development. We analyzed changes made to a product line in typical evolution scenarios by involving the key developers. We used empirical data on observed development activities and impact analyses to derive a trace information model showing frequently desired trace links. We discuss lessons learned and implications for tool developers.},
 author = {Heider, Wolfgang and Vierhauser, Michael and Lettner, Daniela and Grünbacher, Paul},
 booktitle = {2012 Joint Working IEEE/IFIP Conference on Software Architecture and European Conference on Software Architecture},
 doi = {10.1109/WICSA-ECSA.212.8},
 issn = {},
 keywords = {},
 month = {Aug},
 number = {},
 pages = {1-10},
 title = {A Case Study on the Evolution of a Component-based Product Line},
 volume = {},
 year = {2012}
}

@inproceedings{6462648,
 abstract = {Today's large-scale software systems are frequently based on system-of-systems architectures comprising multiple heterogeneous systems. Multi product lines have been presented as an approach to ease their development through systematic reuse. In multi product lines different users and teams are involved in product derivation. Users configure the involved product lines in a collaborative and distributed manner. It is challenging to ensure awareness regarding the configuration choices of users configuring related product lines in such a setting. We present a tool-supported approach that aims at increasing awareness by discovering dependencies and sharing configuration information during the collaborative and distributed product derivation of a multi product line. Our approach uses a bulletin board mechanism for sharing configuration information. It further implements a request-publish-subscribe mechanism for revealing possible dependencies and presenting the information relevant to the users' specific configuration tasks. We evaluated the usability and utility of our approach in a two-phase study involving twelve industrial experts. The evaluation demonstrates the usability and utility of our approach to foster awareness regarding configuration dependencies during the distributed product derivation of a multi product line.},
 author = {Holl, Gerald and Grünbacher, Paul and Elsner, Christoph and Klambauer, Thomas},
 booktitle = {2012 19th Asia-Pacific Software Engineering Conference},
 doi = {10.1109/APSEC.2012.41},
 issn = {1530-1362},
 keywords = {},
 month = {Dec},
 number = {},
 pages = {137-147},
 title = {Supporting Awareness during Collaborative and Distributed Configuration of Multi Product Lines},
 volume = {1},
 year = {2012}
}

@inproceedings{6805425,
 abstract = {Large-scale software-intensive systems are often considered as systems of systems (SoS) comprising multiple heterogeneous but interrelated systems. The engineering of SoS often involves the derivation of system variants from multiple interrelated product lines to meet the overall requirements. If multiple teams and experts are involved in the configuration of these individual systems, their individual configuration choices may conflict with each other or violate constraints. This paper illustrates industrial challenges based on a previously conducted case study on distributed configuration in multi product lines. We then present CoDiM, a tool-supported approach for defining and checking constraints in distributed configuration of an SoS. Our approach is integrated in the product line tool suite DOPLER developed in cooperation with industry partners. An application scenario from a real-world multi product line demonstrates how our approach allows detecting violations of constraints during distributed configuration of an SoS. The approach provides immediate feedback to configurers during product derivation and enables the dynamic definition of constraints even during configuration time to accommodate changes. CoDiM further supports constraint templates which can be parameterized to allow their reuse in different multi product line configurations.},
 author = {Holl, Gerald and Grünbacher, Paul and Elsner, Christoph and Klambauer, Thomas and Vierhauser, Michael},
 booktitle = {2013 20th Asia-Pacific Software Engineering Conference (APSEC)},
 doi = {10.1109/APSEC.2013.54},
 issn = {1530-1362},
 keywords = {},
 month = {Dec},
 number = {},
 pages = {347-354},
 title = {Constraint Checking in Distributed Product Configuration of Multi Product Lines},
 volume = {1},
 year = {2013}
}

@article{Barnes_2002,
 abstract = {There is a growing world-wide trend toward greater collaboration between academia and industry, an activity encouraged by governments as a means of enhancing national competitiveness and wealth creation. Warwick Manufacturing Group (WMG) is well known for its extensive links with industry, and provided an excellent opportunity for a study of management practice within university–industry collaborative research projects. This paper evaluates the findings of six collaborative research projects. The objective was to identify factors which, if managed correctly, increase the probability of a collaboration being perceived as successful by both academic and industrial partners. The outcome was a good practice model for successful university–industry research collaborations.},
 author = {Tina Barnes and Ian Pashby and Anne Gibbons},
 doi = {10.1016/s0263-2373(02)00044-0},
 journal = {European Management Journal},
 month = {jun},
 number = {3},
 pages = {272--285},
 publisher = {Elsevier {BV}},
 title = {Effective University {\textendash} Industry Interaction:},
 url = {https://doi.org/10.1016%2Fs0263-2373%2802%2900044-0},
 volume = {20},
 year = {2002}
}

@article{Dhungana_2010,
 abstract = {The variability of a product line is typically defined in models. However, many existing variability modeling approaches are
rigid and don’t allow sufficient domain-specific adaptations. We have thus been developing a flexible and extensible approach
for defining product line variability models. Its main purposes are to guide stakeholders through product derivation and to
automatically generate product configurations. Our approach is supported by the DOPLER (Decision-Oriented Product Line Engineering for effective Reuse) meta-tool that allows modelers to specify the types of reusable assets, their attributes, and dependencies for their
specific system and context. The aim of this paper is to investigate the suitability of our approach for different domains.
More specifically, we explored two research questions regarding the implementation of variability and the utility of DOPLER
for variability modeling in different domains. We conducted a multiple case study consisting of four cases in the domains
of industrial automation systems and business software. In each of these case studies we analyzed variability implementation
techniques. Experts from our industry partners then developed domain-specific meta-models, tool extensions, and variability
models for their product lines using DOPLER. The four cases demonstrate the flexibility of the DOPLER approach and the extensibility
and adaptability of the supporting meta tool.},
 author = {Deepak Dhungana and Paul Grünbacher and Rick Rabiser},
 doi = {10.1007/s10515-010-0076-6},
 journal = {Automated Software Engineering},
 month = {nov},
 number = {1},
 pages = {77--114},
 publisher = {Springer Science and Business Media {LLC}},
 title = {The {DOPLER} meta-tool for decision-oriented variability modeling: a multiple case study},
 url = {https://doi.org/10.1007%2Fs10515-010-0076-6},
 volume = {18},
 year = {2010}
}

@inproceedings{Rabiser_2012,
 abstract = {Software systems are nowadays often configured by sales people, domain experts, or even customers instead of engineers. Configuration tools communicate the systems' variability to these end users and provide guidance for selecting and customizing the available features. However, even if a configuration tool creates technically correct systems, addressing the specific needs of business-oriented users remains challenging. We analyze existing configuration tools to identify key capabilities for guiding end users and discuss these capabilities using the cognitive dimensions of notations framework. We present an implementation of the capabilities in our configuration tool DOPLER CW. We performed a qualitative investigation on the usefulness of the tool's capabilities for user guidance in product configuration by involving nine business-oriented experts of two industry partners from the domain of industrial automation. We present key results and derive general implications for tool developers.},
 author = {Rick Rabiser and Paul Grünbacher and Martin Lehofer},
 booktitle = {Proceedings of the 27th {IEEE}/{ACM} International Conference on Automated Software Engineering},
 doi = {10.1145/2351676.2351693},
 month = {sep},
 publisher = {{ACM}},
 title = {A qualitative study on user guidance capabilities in product configuration tools},
 url = {https://doi.org/10.1145%2F2351676.2351693},
 year = {2012}
}

@inproceedings{Wright_2010,
 abstract = {Empirical studies that use software repository artifacts have become popular in the last decade due to the ready availability of open source project archives. In this paper, we survey empirical studies in the last three years of ICSE and FSE proceedings, and categorize these studies in terms of open source projects vs. proprietary source projects and the diversity of subject programs used in these studies. Our survey has shown that almost half (49%) of recent empirical studies used solely open source projects. Existing studies either draw general conclusions from these results or explicitly disclaim any conclusions that can extend beyond specific subject software. We conclude that researchers in empirical software engineering must consider the external validity concerns that arise from using only several well-known open source software projects, and that discussion of data source selection is an important discussion topic in software engineering research. Furthermore, we propose a community research infrastructure for software repository benchmarks and sharing the empirical analysis results, in order to address external validity concerns and to raise the bar for empirical software engineering research that analyzes software artifacts.},
 author = {Hyrum K. Wright and Miryung Kim and Dewayne E. Perry},
 booktitle = {Proceedings of the {FSE}/{SDP} workshop on Future of software engineering research},
 doi = {10.1145/1882362.1882446},
 month = {nov},
 publisher = {{ACM}},
 title = {Validity concerns in software engineering research},
 url = {https://doi.org/10.1145%2F1882362.1882446},
 year = {2010}
}

@inproceedings{1509297,
 abstract = {Defect measurement plays a crucial role when assessing quality assurance processes such as inspections and testing. To systematically combine these processes in the context of an integrated quality assurance strategy, measurement must provide empirical evidence on how effective these processes are and which types of defects are detected by which quality assurance process. Typically, defect classification schemes, such as ODC or the Hewlett-Packard scheme, are used to measure defects for this purpose. However, we found it difficult to transfer existing schemes to an embedded software context, where specific document- and defect types have to be considered. This paper presents an approach to define, introduce, and validate a customized defect classification scheme that considers the specifics of an industrial environment. The core of the approach is to combine the software engineering know-how of measurement experts and the domain know-how of developers. In addition to the approach, we present the results and experiences of using the approach in an industrial setting. The results indicate that our approach results in a defect classification scheme that allows classifying defects with good reliability, that allows identifying process improvement actions, and that can serve as a baseline for evaluating the impact of process improvements},
 author = {Freimut, B. and Denger, C. and Ketterer, M.},
 booktitle = {11th IEEE International Software Metrics Symposium (METRICS'05)},
 doi = {10.1109/METRICS.2005.10},
 issn = {1530-1435},
 keywords = {},
 month = {Sep.},
 number = {},
 pages = {10 pp.-19},
 title = {An industrial case study of implementing and validating defect classification for process improvement and quality management},
 volume = {},
 year = {2005}
}

@article{4118655,
 abstract = {Software inspection is a rigorous process for validating software work products that's both efficient and cost effective. However, this process presents challenges that might keep software developers from continuing to implement inspections. From our experience, major reasons for this are poor or missing customization of inspections for given context characteristics and insufficient stakeholder involvement. The TAQtIC (Tailoring Approach for Quality-Driven Inspections) inspection approach lets organizations implement inspections in a sustainable way in a given organizational context. Practitioners can use TAQtIC's underlying concepts to customize inspections for their environment. Experiences from projects using this approach demonstrate how organizations can tailor inspections of their software products},
 author = {Denger, Christian and Shull, Forrest},
 doi = {10.1109/MS.2007.31},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {March},
 number = {2},
 pages = {79-86},
 title = {A Practical Approach for Quality-Driven Inspections},
 volume = {24},
 year = {2007}
}

@inproceedings{915536,
 abstract = {The use of commercial-off-the-shelf (COTS) software has become more and more important in state-of-the-art and state-of-the-practice software and system development. The use of COTS software promises faster time-to-market, reduced development costs, increased productivity, and the possibility for companies to focus on their own core competencies. At the same time, COTS software increases risks, such as the economic instability of the COTS software vendor, unknown quality properties of the COTS software in use, and side-effects of the COTS software on the final product. Typically, COTS-based development, in parallel with the traditional development cycle (e.g. waterfall, spiral), consists of four phases. The first phase (COTS assessment and selection) is the most crucial phase in the COTS-based cycle, since long-term decisions about which COTS software to use in a software system are made there. A late recognition that the "wrong" COTS software was used can become extremely costly for a software organization. This paper presents a repeatable, cost-efficient and systematic method for performing measurement-based COTS assessment and selection. Moreover, cost/benefit analysis results of two industrial pilot projects, in which the method was successfully applied, are presented.},
 author = {Ochs, M. and Pfahl, D. and Chrobok-Diening, G. and Nothhelfer-Kolb, B.},
 booktitle = {Proceedings Seventh International Software Metrics Symposium},
 doi = {10.1109/METRIC.2001.915536},
 issn = {1530-1435},
 keywords = {},
 month = {April},
 number = {},
 pages = {285-296},
 title = {A method for efficient measurement-based COTS assessment and selection method description and evaluation results},
 volume = {},
 year = {2001}
}

@inproceedings{Basili_2002,
 abstract = {For 25 years the NASA/GSFC Software Engineering Laboratory (SEL) has been a major resource in software process improvement activities. But due to a changing climate at NASA, agency reorganization, and budget cuts, the SEL has lost much of its impact. In this paper we describe the history of the SEL and give some lessons learned on what we did right, what we did wrong, and what others can learn from our experiences. We briefly describe the research that was conducted by the SEL, describe how we evolved our understanding of software process improvement, and provide a set of lessons learned and hypotheses that should enable future groups to learn from and improve on our quarter century of experiences.},
 author = {Victor R. Basili and Frank E. McGarry and Rose Pajerski and Marvin V. Zelkowitz},
 booktitle = {Proceedings of the 24th international conference on Software engineering  - {ICSE} {\textquotesingle}02},
 doi = {10.1145/581339.581351},
 publisher = {{ACM} Press},
 title = {Lessons learned from 25 years of process improvement},
 url = {https://doi.org/10.1145%2F581339.581351},
 year = {2002}
}

@inproceedings{Ochs_2001,
 abstract = {The use of commercial-off-the-shelf (COTS) software has become more and more important in state-of-the-art and state-of-the-practice software and system development. The use of COTS software promises faster time-to-market, reduced development costs, increased productivity, and the possibility for companies to focus on their own core competencies. At the same time, COTS software increases risks, such as the economic instability of the COTS software vendor, unknown quality properties of the COTS software in use, and side-effects of the COTS software on the final product. Typically, COTS-based development, in parallel with the traditional development cycle (e.g. waterfall, spiral), consists of four phases. The first phase (COTS assessment and selection) is the most crucial phase in the COTS-based cycle, since long-term decisions about which COTS software to use in a software system are made there. A late recognition that the “wrong” COTS software was used can become extremely costly for a software organization. This paper presents a repeatable, cost-efficient and systematic method for performing measurement-based COTS assessment and selection. Moreover, cost/benefit analysis results of two industrial pilot projects, in which the method was successfully applied, are presented},
 author = {M. Ochs and D. Pfahl and G. Chrobok-Diening and B. Nothhelfer-Kolb},
 booktitle = {Proceedings Seventh International Software Metrics Symposium},
 doi = {10.1109/metric.2001.915536},
 publisher = {{IEEE}},
 title = {A method for efficient measurement-based {COTS} assessment and selection method description and evaluation results},
 url = {https://doi.org/10.1109%2Fmetric.2001.915536},
 year = {2001}
}

@article{Pfleeger_1999,
 abstract = {Technology transfer in software engineering involves more than a new idea or evidence that it works. This paper illustrates how technology transfer requires a good idea, the generation of evidence, analysis of that evidence, good packaging and support, and careful consideration of the audience for the technology. By learning from other disciplines, we present a model of technology transfer that can be tailored to a particular organisation's needs.},
 author = {S.L Pfleeger},
 doi = {10.1016/s0164-1212(99)00031-x},
 journal = {Journal of Systems and Software},
 month = {jul},
 number = {2-3},
 pages = {111--124},
 publisher = {Elsevier {BV}},
 title = {Understanding and improving technology transfer in software engineering},
 url = {https://doi.org/10.1016%2Fs0164-1212%2899%2900031-x},
 volume = {47},
 year = {1999}
}

@inproceedings{Trendowicz_2006,
 abstract = {Cost estimation is a very crucial field for software developing companies. The acceptance of an estimation technique is highly dependent on estimation accuracy. Often, this accuracy is only determined after an initial application. Possible further steps for improving the underlying estimation model typically do not influence the decision on whether to discard the technique or deploy it. In addition, most estimation techniques do not explicitly support the evolution of the underlying estimation model in an iterative manner. This increases the risk of overlooking some important cost drivers or data inconsistencies. This paper presents an enhanced process for developing a CoBRA® cost estimation model by systematically including iterative analysis and feedback cycles, and its evaluation in a software development unit of Oki Electric Industry Co., Ltd., Japan. During the model improvement cycles, estimation accuracy was improved from an initial 120% down to 14%. In addition, lessons learned with the iterative development approach are described.},
 author = {Adam Trendowicz and Jens Heidrich and Jürgen Münch and Yasushi Ishigai and Kenji Yokoyama and Nahomi Kikuchi},
 booktitle = {Proceedings of the 28th international conference on Software engineering},
 doi = {10.1145/1134285.1134332},
 month = {may},
 publisher = {{ACM}},
 title = {Development of a hybrid cost estimation model in an iterative manner},
 url = {https://doi.org/10.1145%2F1134285.1134332},
 year = {2006}
}

@article{Walter_2002,
 abstract = {},
 author = {Achim Walter and Michael Auer and Hans Georg Gemunden},
 doi = {10.1504/ijeim.2002.000485},
 journal = {International Journal of Entrepreneurship and Innovation Management},
 number = {2/3},
 pages = {268},
 publisher = {Inderscience Publishers},
 title = {The impact of personality, competence, and activities of academic entrepreneurs on technology transfer success},
 url = {https://doi.org/10.1504%2Fijeim.2002.000485},
 volume = {2},
 year = {2002}
}

@incollection{1,
 abstract = {Information Systems (IS) are complex artifacts which could be viewed as playing the role of an interface between the organizational structure and processes and the technological capabilities. IS design is influenced by—and has an influence on—its outer environment: organizational context. Much of past research in IS is of explanatory nature and has largely focused on the processes and functions of outer environment, including organizations and individuals. There is not sufficient theoretical elaboration on the organizational and technological connections of the IS artifacts. Some of the most prominent theoretical models of IS do not incorporate the very nature of information systems to a substantial extent. The information content of these models is also questionable. IS research has been criticized by some members of the research community for lack of identity and lack of relevance.},
 booktitle = {Design-Type Research in Information Systems},
 doi = {10.4018/978-1-4666-0131-4.ch003},
 pages = {51--75},
 publisher = {{IGI} Global},
 title = {Research in Information Systems},
 url = {https://doi.org/10.4018%2F978-1-4666-0131-4.ch003}
}

@article{1702325,
 abstract = {The Cleanroom software development approach is intended to produce highly reliable software by integrating formal methods for specification and design, nonexecution-based program development, and statistically based independent testing. In an empirical study, 15 three-person teams developed versions of the same software system (800-2300 source lines); ten teams applied Cleanroom, while five applied a more traditional approach. This analysis characterizes the effect of Cleanroom on the delivered product, the software development process, and the developers.},
 author = {Selby, R.W. and Basili, V.R. and Baker, F.T.},
 doi = {10.1109/TSE.1987.233525},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {Sep.},
 number = {9},
 pages = {1027-1037},
 title = {Cleanroom Software Development: An Empirical Evaluation},
 volume = {SE-13},
 year = {1987}
}

@article{1982,
 abstract = {},
 doi = {10.1016/0377-2217(82)90206-5},
 journal = {European Journal of Operational Research},
 month = {dec},
 number = {4},
 pages = {405--407},
 publisher = {Elsevier {BV}},
 title = {Systems thinking, systems practice},
 url = {https://doi.org/10.1016%2F0377-2217%2882%2990206-5},
 volume = {11},
 year = {1982}
}

@article{1985,
 abstract = {},
 doi = {10.1016/0378-7206(85)90013-8},
 journal = {Information {\&}amp$\mathsemicolon$ Management},
 month = {oct},
 number = {3},
 pages = {189--192},
 publisher = {Elsevier {BV}},
 title = {Research methods in information systems},
 url = {https://doi.org/10.1016%2F0378-7206%2885%2990013-8},
 volume = {9},
 year = {1985}
}

@article{1990,
 abstract = {},
 doi = {10.1016/0377-2217(90)90286-k},
 journal = {European Journal of Operational Research},
 month = {jul},
 number = {2},
 pages = {264},
 publisher = {Elsevier {BV}},
 title = {Professional Systems Development - Experience, ideas and action},
 url = {https://doi.org/10.1016%2F0377-2217%2890%2990286-k},
 volume = {47},
 year = {1990}
}

@article{1993,
 abstract = {},
 doi = {10.5860/choice.30-4486},
 journal = {Choice Reviews Online},
 month = {apr},
 number = {08},
 pages = {30--4486--30--4486},
 publisher = {American Library Association},
 title = {Process innovation: reengineering work through information technology},
 url = {https://doi.org/10.5860%2Fchoice.30-4486},
 volume = {30},
 year = {1993}
}

@book{1997,
 abstract = {This book contains the papers presented and discussed at the conference that was held in May/June 1997, in Philadelphia, Pennsylvania, USA, and that was sponsored by Working Group 8.2 of the International Federation for Information Processing. IFIP established 8.2 as a group concerned with the interaction of information systems and the organization.
Information Systems and Qualitative Research is essential reading for professionals and students working in information systems in a business environment, such as systems analysts, developers and designers, data administrators, and senior executives in all business areas that use information technology, as well as consultants in the fields of information systems, management, and quality management.},
 doi = {10.1007/978-0-387-35309-8},
 editor = {Allen S. Lee and Jonathan Liebenau and Janice I. DeGross},
 publisher = {Springer {US}},
 title = {Information Systems and Qualitative Research},
 url = {https://doi.org/10.1007%2F978-0-387-35309-8},
 year = {1997}
}

@article{2014,
 abstract = {A description is given of a software-process maturity framework that has been developed to provide the US Department of Defense with a means to characterize the capabilities of software-development organizations. This software-development process-maturity model reasonably represents the actual ways in which software-development organizations improve. It provides a framework for assessing these organizations and identifying the priority areas for immediate improvement. It also helps identify those places where advanced technology can be most valuable in improving the software-development process. The framework can be used by any software organization to assess its own capabilities and identify the most important areas for improvement.<>},
 author = {Humphrey, W.S.},
 doi = {10.1109/52.2014},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {March},
 number = {2},
 pages = {73-79},
 title = {Characterizing the software process: a maturity framework},
 volume = {5},
 year = {1988}
}

@inproceedings{205401,
 abstract = {The authors critically review systems development in information systems (IS) research. Several classification schemes of research are described and systems development is identified as a developmental, engineering, and formulative type of research. A framework of research is proposed to explain the dual nature of systems development as a research methodology and a research domain in IS research. Progress in several disciplinary areas is reviewed to provide a basis to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, the basic method is applying the systems development research methodology, is then discussed. A framework to classify IS research domain and various research methodologies in studying systems development is presented. It is suggested that systems development and empirical research methodologies are complementary to each other. It is further proposed that an integrated multidimensional and multimethodological approach will generate fruitful research results in IS research.<>},
 author = {Nunamaker, J.F. and Chen, M.},
 booktitle = {Twenty-Third Annual Hawaii International Conference on System Sciences},
 doi = {10.1109/HICSS.1990.205401},
 issn = {},
 keywords = {},
 month = {Jan},
 number = {},
 pages = {631-640 vol.3},
 title = {Systems development in information systems research},
 volume = {3},
 year = {1990}
}

@article{5010238,
 abstract = {In this experiment, seven software teams developed versions of the same small-size (2000-4000 source instruction) application software product. Four teams used the Specifying approach. Three teams used the Prototyping approach. The main results of the experiment were the following. 1) Prototyping yielded products with roughly equivalent performance, but with about 40 percent less code and 45 percent less effort. 2) The prototyped products rated somewhat lower on functionality and robustness, but higher on ease of use and ease of learning. 3) Specifying produced more coherent designs and software that was easier to integrate. The paper presents the experimental data supporting these and a number of additional conclusions.},
 author = {Boehm, Barry W. and Gray, Terence E. and Seewaldt, Thomas},
 doi = {10.1109/TSE.1984.5010238},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {May},
 number = {3},
 pages = {290-303},
 title = {Prototyping Versus Specifying: A Multiproject Experiment},
 volume = {SE-10},
 year = {1984}
}

@article{5010301,
 abstract = {An effective data collection method for evaluating software development methodologies and for studying the software development process is described. The method uses goal-directed data collection to evaluate methodologies with respect to the claims made for them. Such claims are used as a basis for defining the goals of the data collection, establishing a list of questions of interest to be answered by data analysis, defining a set of data categorization schemes, and designing a data collection form. The data to be collected are based on the changes made to the software during development, and are obtained when the changes are made. To ensure accuracy of the data, validation is performed concurrently with software development and data collection. Validation is based on interviews with those people supplying the data. Results from using the methodology show that data validation is a necessary part of change data collection. Without it, as much as 50 percent of the data may be erroneous. Feasibility of the data collection methodology was demonstrated by applying it to five different projects in two different environments. The application showed that the methodology was both feasible and useful.},
 author = {Basili, Victor R. and Weiss, David M.},
 doi = {10.1109/TSE.1984.5010301},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {Nov},
 number = {6},
 pages = {728-738},
 title = {A Methodology for Collecting Valid Software Engineering Data},
 volume = {SE-10},
 year = {1984}
}

@article{6191,
 abstract = {A discussion is presented of the two primary ways of understanding software costs. The black-box or influence-function approach provides useful experimental and observational insights on the relative software productivity and quality leverage of various management, technical, environmental, and personnel options. The glass-box or cost distribution approach helps identify strategies for integrated software productivity and quality improvement programs using such structures as the value chain and the software productivity opportunity tree. The individual strategies for improving software productivity are identified. Issues related to software costs and controlling them are examined and discussed. It is pointed out that a good framework of techniques exists for controlling software budgets, schedules, and work completed, but that a great deal of further progress is needed to provide an overall set of planning and control techniques covering software product qualities and end-user system objectives.<>},
 author = {Boehm, B.W. and Papaccio, P.N.},
 doi = {10.1109/32.6191},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {Oct},
 number = {10},
 pages = {1462-1477},
 title = {Understanding and controlling software costs},
 volume = {14},
 year = {1988}
}

@article{6312975,
 abstract = {A framework is presented for analyzing most of the experimental work performed in software engineering over the past several years. The framework of experimentation consists of four categories corresponding to phases of the experimentation process: definition, planning, operation, and interpretation. A variety of experiments are described within the framework and their contribution to the software engineering discipline is discussed. Some recommendations for the application of the experimental process in software engineering are included.},
 author = {Basili, Victor R. and Selby, Richard W. and Hutchens, David H.},
 doi = {10.1109/TSE.1986.6312975},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {July},
 number = {7},
 pages = {733-743},
 title = {Experimentation in software engineering},
 volume = {SE-12},
 year = {1986}
}

@article{6312991,
 abstract = {A careful reader, Max Stern of Teradata Corporation, has brought to our attention two errors in the above paper.1 On page 253 in the second paragraph under point 4) the text reads, “A purely digital or purely hybrid computer is a special case of this general module.” It should read, “A purely digital or purely analog computer is a special case of this general model.”},
 author = {Parnas, David Lorge and Clements, Paul C.},
 doi = {10.1109/TSE.1986.6312991},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 keywords = {},
 month = {Aug},
 number = {8},
 pages = {874-874},
 title = {Correction to “a rational design process: How and why to fake it”},
 volume = {SE-12},
 year = {1986}
}

@article{646884,
 abstract = {Most everyone in our field acknowledges that software process improvement cannot succeed unless management is committed to implementing it. Fortunately, the move to SPI can be a two-way street, initiated as easily from the bottom up as from the top down. Taking this bottom-up approach, I present some tricks that practitioners down in the trenches can use to win upper management's approval of and support for SPI.},
 author = {Jakobsen, A.B.},
 doi = {10.1109/52.646884},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Jan},
 number = {1},
 pages = {64-68},
 title = {Bottom up process improvement tricks},
 volume = {15},
 year = {1998}
}

@inproceedings{926774,
 abstract = {A growing number of IT organizations pursue a systematic strategy to mature their software operation. These efforts have severe implications for their customers or clients both in terms of opportunities and challenges. As a consequence a number of customer related models have emerged as a supplement to the software process centered maturity models. This paper addresses the improvement of the customer-supplier relation in IT development on a theoretical, a normative, and a practical level. It presents theoretically founded insights into the nature of customer-supplier collaborations. This knowledge is used (1) to evaluate and compare normative models for how to improve customer-supplier relations and (2) to explore practical ways to improve the relation between an IT organization and its customers. The paper is concluded with a discussion of implications for research and practice.},
 author = {Bjerknes, G. and Mathiassen, L.},
 booktitle = {Proceedings of the 33rd Annual Hawaii International Conference on System Sciences},
 doi = {10.1109/HICSS.2000.926774},
 issn = {},
 keywords = {},
 month = {Jan},
 number = {},
 pages = {10 pp.-},
 title = {Improving the customer-supplier relation in IT development},
 volume = {},
 year = {2000}
}

@article{Applegate_1999,
 abstract = {},
 author = {Lynda M. Applegate},
 doi = {10.2307/249402},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {1},
 publisher = {{JSTOR}},
 title = {Rigor and Relevance in {MIS} Research-Introduction},
 url = {https://doi.org/10.2307%2F249402},
 volume = {23},
 year = {1999}
}

@article{Applegate_1999,
 abstract = {The various aspects of Marilyn Moore's career are discussed. Moore had graduated from Barker University in June 1996 and did Ph.D. in business administration, majoring in management information systems and decision sciences. Moore worked on a project to redesign the company's order fulfillment process which gained high-level visibility and Moore had an opportunity to work with division-level seniormanagers in all parts of the Fortune 100 consumer products firm. Moore started writing a paper from her dissertation and submitted it to a top tier journal which was rejected. Moore returned to Fortune 100 consumer products firm and designed a research project.},
 author = {Lynda M. Applegate and John L. King},
 doi = {10.2307/249404},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {17},
 publisher = {{JSTOR}},
 title = {Rigor and Relevance: Careers on the Line},
 url = {https://doi.org/10.2307%2F249404},
 volume = {23},
 year = {1999}
}

@article{Avison_1991,
 abstract = {This paper describes aspects of applied research related to the development of information systems. There is a proliferation of information systems development methodologies and some confusion has resulted. Methodologies are classified into six broad themes, but experience suggests that no methodology can be appropriate to all situations. A contingency framework called Multiview has been devised which includes descriptions of relevant techniques and tools. The analysts and users select those aspects of the approach which are appropriate to the context, in effect creating a unique methodology for each application. The approach has been used in a number of applications and these experiences have led to modifications of the framework. In the cycle of action research there is close interaction between theory and practice and between the researcher and the practitioner. The paper describes the learning process and discusses some lessons learned from this experience. It also puts forward conclusions about the methodology framework, the strengths and problems of using a contingency approach, and of action research in information systems.},
 author = {D. E. Avison},
 doi = {10.1093/comjnl/34.2.98},
 journal = {The Computer Journal},
 month = {feb},
 number = {2},
 pages = {98--112},
 publisher = {Oxford University Press ({OUP})},
 title = {Information Systems Development Research: An Exploration of Ideas in Practice},
 url = {https://doi.org/10.1093%2Fcomjnl%2F34.2.98},
 volume = {34},
 year = {1991}
}

@article{Avison_2001,
 abstract = {Action research (AR), which emphasises collaboration between researchers and practitioners, is a qualitative research method that has much potential for the information systems (IS) field. AR studies of IS phenomena are now beginning to be published in the IS research literature. However, the rigour of many AR studies in IS can be improved. When AR has been published, the findings have frequently been emphasised at the expense of the process. In this article, we look at the process in AR projects, and look at some of the key choices and alternatives in controlling AR. We discuss three aspects of control: the procedures for initiating an AR project, those for determining authority within the project, and the degree of formalisation. We analyse seven recent AR projects in IS and from this analysis distil recommendations for determining these control structures.},
 author = {David Avison and Richard Baskerville and Michael Myers},
 doi = {10.1108/09593840110384762},
 journal = {Information Technology {\&}amp$\mathsemicolon$ People},
 month = {mar},
 number = {1},
 pages = {28--45},
 publisher = {Emerald},
 title = {Controlling action research projects},
 url = {https://doi.org/10.1108%2F09593840110384762},
 volume = {14},
 year = {2001}
}

@incollection{Bakehouse_2000,
 abstract = {The first section of this paper provides a view of the relationship between research and reality. Central to this debate is the notion of two separate and sometimes competing approaches to solve real life problems, theory and practise. The last three or so decades has witnessed the development of numerous methodologies which vary across a wide spectrum from the “very hard” to the “very soft” most claiming to have practical benefits in the real world. An area of Systems Science that has grown quickly amongst all the confusion is that of Information Systems, a new and highly dynamic subject area where academics and practitioners often fail to agree at any level about things as fundamental as the meanings of ‘information’ and ‘system’. There is ample evidence to show that in the world of Business Information Systems, technologists do not understand the world of business and vice-versa. The final section of this paper describes an ongoing action research program that spans several sectors of commerce and industry. The methods, tools and techniques adopted in this study are drawn from numerous paradigms and disciplines; many have been specifically adapted for the research program. These tools and techniques range from participant observation, SWOT analysis, information problem classification, phenotypes of erroneous action, human error modelling through to psychometric testing accompanied by “standard” information systems tools. Central to the research program is the concept of building links between research and reality via empirical research.},
 author = {George J. Bakehouse},
 booktitle = {{BIS} 2000},
 doi = {10.1007/978-1-4471-0761-3_7},
 pages = {109--120},
 publisher = {Springer London},
 title = {Empirical Research in Information Systems},
 url = {https://doi.org/10.1007%2F978-1-4471-0761-3_7},
 year = {2000}
}

@article{Bansler_1993,
 abstract = {We review Structured Analysis as presented by Yourdon and DeMarco. First, we examine the implicit assumptions embodied in the method about the nature of organizations, work processes, and design. Following this we present the results of an exploratory study, conducted to find out bow the method is applied in practice. This study reveals that while some of the tools of Structured Analysis---notably the data flow diagrams---are used and combined with other tools, the designers do not follow the analysis and design procedures prescribed by the method. Our findings suggest that there is a gap between the way systems development is portrayed in the norm ative technical literature and the way in which it is carried out.},
 author = {Jorgen P. Bansler and Keld B{\o}dker},
 doi = {10.1145/130226.148055},
 journal = {{ACM} Transactions on Information Systems},
 month = {apr},
 number = {2},
 pages = {165--193},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {A reappraisal of structured analysis},
 url = {https://doi.org/10.1145%2F130226.148055},
 volume = {11},
 year = {1993}
}

@article{Baskerville_1996,
 abstract = {This article presents a new approach to the management of evolutionary prototyping projects. The prototyping approach to systems development emphasizes learning and facilitates meaningful communication between systems developers and users. These benefits are important for rapid creation of flexible, usable information resources that are well-tuned to present and future business needs. The main unsolved problem in prototyping is the difficulty in controlling such projects. This problem severely limits the range of practical projects in which prototyping can be used. The new approach suggested in this article uses an explicit risk mitigation model and management process that energizes and enhances the value of prototyping in technology delivery. An action research effort validates this risk analysis approach as one that focuses management attention on consequences and priorities inherent in a prototyping situation. This approach enables appropriate risk resolution strategies to be placed in effect before the prototyping process breaks down. It facilitates consensus building through collaborative decision making and is consistent with a high degree of user involvement.},
 author = {Richard L. Baskerville and Jan Stage},
 doi = {10.2307/249565},
 journal = {{MIS} Quarterly},
 month = {dec},
 number = {4},
 pages = {481},
 publisher = {{JSTOR}},
 title = {Controlling Prototype Development through Risk Analysis},
 url = {https://doi.org/10.2307%2F249565},
 volume = {20},
 year = {1996}
}

@article{Baskerville_1996,
 abstract = {This paper reviews the origins, techniques and roles associated with action research into information systems (IS). Many consider the approach to be the paragon of post-positivist research methods, yet it has a cloudy history among the social sciences. The paper summarizes the rigorous approach to action research and suggests certain domains of ideal use (such as systems development methodology). For those faced with conducting, reviewing or examining action research, the paper discusses various problems, opportunities and strategies.},
 author = {Richard L. Baskerville and A. Trevor Wood-Harper},
 doi = {10.1177/026839629601100305},
 journal = {Journal of Information Technology},
 month = {sep},
 number = {3},
 pages = {235--246},
 publisher = {{SAGE} Publications},
 title = {A Critical Perspective on Action Research as a Method for Information Systems Research},
 url = {https://doi.org/10.1177%2F026839629601100305},
 volume = {11},
 year = {1996}
}

@article{Benbasat_1980,
 abstract = {This article presents the results of a study which analyzes skills perceived as useful by information systems (IS) managers and systems analysts in IS organizations of different levels of maturity. These IS skills were examined under two major subgroups of generalist/managerial and specialist/technical skills as well as under more detailed categories of organizations, people, society, systems, computers, and models skills. Generalist, i.e., organizational and people skills, were rated highest. Based on these rankings, which deviated little between managers and analysts and across the maturity spectrum, recommendations concerning graduate IS curriculum are suggested.},
 author = {Izak Benbasat and Albert S. Dexter and Robert W. Mantha},
 doi = {10.2307/248865},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {21},
 publisher = {{JSTOR}},
 title = {Impact of Organizational Maturity on Information System Skill Needs},
 url = {https://doi.org/10.2307%2F248865},
 volume = {4},
 year = {1980}
}

@article{Benbasat_1999,
 abstract = {This commentary discusses why most IS acade- mic research today lacks relevance to practice and suggests tactics, procedures, and guidelines that the IS academic community might follow in their research efforts and articles to introduce rel- evance to practitioners. The commentary begins by defining what is meant by relevancy in the context of academic research. It then explains why there is a lack of attention to relevance with- in the IS scholarly literature. Next, actions that can be taken to make relevance a more central aspect of IS research and to communicate impli- cations of IS research more effectively to IS pro- fessionals are suggested.},
 author = {Izak Benbasat and Robert W. Zmud},
 doi = {10.2307/249403},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {3},
 publisher = {{JSTOR}},
 title = {Empirical Research in Information Systems: The Practice of Relevance},
 url = {https://doi.org/10.2307%2F249403},
 volume = {23},
 year = {1999}
}

@article{Boland_1978,
 abstract = {Given that user involvement is important in system design, this study addresses the as yet unexplored question of how a user should be involved in the system design process. Two radically different processes of interaction between a systems designer and a manager were compared in an information system design exercise.
In one interaction process, the designer conducted a traditional interview of the manager. He asked questions, analyzed data and made suggestions. In the alternative interaction process, there was an initial sharing of information and mutual suggestions, followed by a critique of each other's suggestions.
The study found that for this ill-structured problem: The alternative interaction process produced higher quality designs with important implementation advantages. The two interaction processes produced designs which used different types of organization control strategies. These results may be due to a problem finding contingency—different processes of interaction may help to define different problems, and thereby produce different, but equally rational, solutions.
For the management of organization design, the process of interacting with users has important implications for the quality of the resulting design, the type of organization control strategy employed, and the subsequent implementation of the system.},
 author = {Richard J. Boland},
 doi = {10.1287/mnsc.24.9.887},
 journal = {Management Science},
 month = {may},
 number = {9},
 pages = {887--898},
 publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
 title = {The Process and Product of System Design},
 url = {https://doi.org/10.1287%2Fmnsc.24.9.887},
 volume = {24},
 year = {1978}
}

@article{Checkoway_1985,
 abstract = {},
 author = {Barry Checkoway and Donald A. Schon},
 doi = {10.2307/3324262},
 journal = {Journal of Policy Analysis and Management},
 number = {3},
 pages = {476},
 publisher = {{JSTOR}},
 title = {The Reflective Practitioner: How Professionals Think in Action},
 url = {https://doi.org/10.2307%2F3324262},
 volume = {4},
 year = {1985}
}

@article{Chiasson_2001,
 abstract = {In one particular action research (AR) methodology, information systems prototyping (ISP), the goals are to involve the researcher in a facilitative and collaborative role with stakeholders in the development of an information system that satisfies their collective needs. But what happens when political and structural conflict and coercive action erupts? This article features an AR case, where the development of an electronic patient record in a heart clinic, resulted in a period of intense structural conflict, and the dismissal of an organizational member. Further analysis suggests that four factors can explain these unusual outcomes and their relationship with the use of an ISP method. These include: the specification of measures and perceptions of success within the AR method (goals); general problems with the AR methodology and/or its clear delineation (processes); problems in using a particular AR methodology in a specific time and place (contingency); and problems with the researcher’s implementation of the AR processes (implementation). The study also highlights a number of areas for development of ISP.},
 author = {Mike Chiasson and Albert S. Dexter},
 doi = {10.1108/09593840110384799},
 journal = {Information Technology {\&}amp$\mathsemicolon$ People},
 month = {mar},
 number = {1},
 pages = {91--108},
 publisher = {Emerald},
 title = {System development conflict during the use of an information systems prototyping method of action research},
 url = {https://doi.org/10.1108%2F09593840110384799},
 volume = {14},
 year = {2001}
}

@article{Ciborra_1994,
 abstract = {Most accounts of computer-based innovation in organizational settings assume a naive picture of organizational change, overlooking events, features, and behaviors that, though unexpected and puzzling, may be the sources of inventions, new knowledge, new organizational routines and arrangements. The ambivalent, untidy, and often unpredictable character of IT-based innovation and change is hardly captured, even by more recent theoretical approaches that have nevertheless provided a deeper understanding of the complex interaction between technology and organizations. Based on field observations of the failures and successes during a major systems development effort in a large European computer manufacturer, we tell a different story: We submit that failures at innovation, surprises, and a whole range of related phenomena can be accounted for by introducing the notion of formative context, that is, the set of institutional arrangements and cognitive imageries that inform the actors' practical and reasoning routines in organizations. Limited capability to inquire into formative contexts is responsible for the actors' limited learning, irrespective of their strategies, interests, espoused theories, and methods. Still, we suggest, plenty of opportunities for innovation lie in the open, pasted-up nature of formative contexts and a new vision of design based on “context-making” interventions can bring them to light.},
 author = {Claudio U. Ciborra and Giovan Francesco Lanzara},
 doi = {10.1016/0959-8022(94)90005-1},
 journal = {Accounting, Management and Information Technologies},
 month = {apr},
 number = {2},
 pages = {61--86},
 publisher = {Elsevier {BV}},
 title = {Formative contexts and information technology: Understanding the dynamics of innovation in organizations},
 url = {https://doi.org/10.1016%2F0959-8022%2894%2990005-1},
 volume = {4},
 year = {1994}
}

@article{Curtis_1988,
 abstract = {The problems of designing large software systems were studied through interviewing personnel from 17 large projects. A layered behavioral model is used to analyze how three of these problems—the thin spread of application domain knowledge, fluctuating and conflicting requirements, and communication bottlenecks and breakdowns—affected software productivity and quality through their impact on cognitive, social, and organizational processes.},
 author = {Bill Curtis and Herb Krasner and Neil Iscoe},
 doi = {10.1145/50087.50089},
 journal = {Communications of the {ACM}},
 month = {nov},
 number = {11},
 pages = {1268--1287},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {A field study of the software design process for large systems},
 url = {https://doi.org/10.1145%2F50087.50089},
 volume = {31},
 year = {1988}
}

@article{Davenport_1999,
 abstract = {The various aspects of information system research are discussed. The most familiar model of academically accepted releavant research is the "applied theory" approach, championed by Bob Zmud, in which researchers apply appropriate academic theories to practical problems. Two different models of practical research are evaluation researh which applies practical and theoretical criteria to the assessment of an interventsion and policy research which focuses on resolving an identified policy problem. According to Benbasat and Zmud IS academics should support these journals by submitting research to them and by counting them heavily in promotion and tenure evaluations.},
 author = {Thomas H. Davenport and M. Lynne Markus},
 doi = {10.2307/249405},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {19},
 publisher = {{JSTOR}},
 title = {Rigor vs. Relevance Revisited: Response to Benbasat and Zmud},
 url = {https://doi.org/10.2307%2F249405},
 volume = {23},
 year = {1999}
}

@article{Galliers_1987,
 abstract = {An abstract is not available.},
 author = {Robert D. Galliers and Frank F. Land},
 doi = {10.1145/32206.315753},
 journal = {Communications of the {ACM}},
 month = {nov},
 number = {11},
 pages = {901--902},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Viewpoint: choosing appropriate information systems research methodologies},
 url = {https://doi.org/10.1145%2F32206.315753},
 volume = {30},
 year = {1987}
}

@incollection{Galliers_2002,
 abstract = {},
 author = {Robert D. Galliers and Frank F. Land},
 booktitle = {Qualitative Research in Information Systems},
 doi = {10.4135/9781849209687.n2},
 pages = {13--17},
 publisher = {{SAGE} Publications, Ltd},
 title = {Choosing Appropriate Information Systems Research Methodologies},
 url = {https://doi.org/10.4135%2F9781849209687.n2},
 year = {2002}
}

@article{Gough_1991,
 abstract = {},
 author = {T. G. Gough and Peter Checkland and Jim Scholes},
 doi = {10.2307/2583669},
 journal = {The Journal of the Operational Research Society},
 month = {sep},
 number = {9},
 pages = {818},
 publisher = {{JSTOR}},
 title = {Soft Systems Methodology in Action},
 url = {https://doi.org/10.2307%2F2583669},
 volume = {42},
 year = {1991}
}

@article{Gould_1985,
 abstract = {This article is both theoretical and empirical. Theoretically, it describes three principles of system design which we believe must be followed to produce a useful and easy to use computer system. These principles are: early and continual focus on users; empirical measurement of usage; and iterative design whereby the system (simulated, prototype, and real) is modified, tested, modified again, tested again, and the cycle is repeated again and again. This approach is contrasted to other principled design approaches, for example, get it right the first time, reliance on design guidelines. Empirically, the article presents data which show that our design principles are not always intuitive to designers; identifies the arguments which designers often offer for not using these principles—and answers them; and provides an example in which our principles have been used successfully.},
 author = {John D. Gould and Clayton Lewis},
 doi = {10.1145/3166.3170},
 journal = {Communications of the {ACM}},
 month = {mar},
 number = {3},
 pages = {300--311},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Designing for usability:  key principles and what designers think},
 url = {https://doi.org/10.1145%2F3166.3170},
 volume = {28},
 year = {1985}
}

@incollection{Hirschheim_1992,
 abstract = {},
 author = {Rudy Hirschheim and Heinz K. Klein},
 booktitle = {Advances in Computers},
 doi = {10.1016/s0065-2458(08)60328-9},
 pages = {293--392},
 publisher = {Elsevier},
 title = {Paradigmatic Influences on Information Systems Development Methodologies: Evolution and Conceptual Advances},
 url = {https://doi.org/10.1016%2Fs0065-2458%2808%2960328-9},
 year = {1992}
}

@book{Hirschheim_1995,
 abstract = {Information systems development is not merely a technical intervention but involves social and ethical dilemmas that affect the human, social and organizational domains. To demonstrate this point, the authors conduct a thorough and substantive description and analysis of the conceptual and philosophical underpinnings of systems development. In particular they analyse a number of systems development methodologies including structured methods, prototyping, ETHICS and Soft Systems Methodology to reveal the underlying conceptual and philosophical foundations. The book provides an in-depth analysis of data modelling theory and its links with theories of language and cognition. It offers a framework to describe and analyse different systems development approaches and to explain their strengths and weaknesses. The book is aimed at graduate students taking courses in information systems and data modelling, but will also appeal to information systems managers and professionals for whom the summary of methodologies will be useful.},
 author = {Rudy Hirschheim and Heinz K. Klein and Kalle Lyytinen},
 doi = {10.1017/cbo9780511895425},
 month = {oct},
 publisher = {Cambridge University Press},
 title = {Information Systems Development and Data Modeling},
 url = {https://doi.org/10.1017%2Fcbo9780511895425},
 year = {1995}
}

@article{Hirschheim_1996,
 abstract = {In this paper we explore the intellectual structures upon which the field of information systems development (ISD) is cultivated. The conceptual base of our work comes from the social action theories of Habermas and Etzioni. We propose a framework which reconceptualizes the field in terms of domains, orientations, object systems, and development strategies. Our analysis not only justifies the reflection of the field as a so-called “fragmented adhocracy”, but also shows why this is so: because IS researchers' mind sets fundamentally differ in terms of how problems are formulated and consequently solved. The intellectual structures of our framework suggest nine conceptual frames which mold these mind sets. Each frame acts as a lens and embraces a different development strategy which distinguishes itself in its dominant orientation of control, sense-making and argumentation, respectively. The framework organizes the field into interrelated sets of intellectual communities, and in so doing, acts as a vehicle for conceptualizing core research issues and identifying future research directions. The paper suggests an intellectual base for penetrating the ambiguities which envelope underresearched islands of ISD.},
 author = {Rudy Hirschheim and Heinz K. Klein and Kalle Lyytinen},
 doi = {10.1016/0959-8022(96)00004-5},
 journal = {Accounting, Management and Information Technologies},
 month = {jan},
 number = {1-2},
 pages = {1--64},
 publisher = {Elsevier {BV}},
 title = {Exploring the intellectual structures of information systems development: A social action theoretic analysis},
 url = {https://doi.org/10.1016%2F0959-8022%2896%2900004-5},
 volume = {6},
 year = {1996}
}

@article{Humphrey_1989,
 abstract = {This report describes the MedIndEx System, a prototype for interactive knowledge-based indexing of the medical literature, being developed in an ongoing research project at the Lister Hill National Center for Biomedical Communications, National Library of Medicine. We first review current indexing practice, which, although performed interactively, relies heavily on published tools. We then discuss knowledge-based systems using frames. The prototype, which uses knowledge-base (KB) frames to guide indexers in completing indexing frames, defined as KB frames linked to specific documents, is described subsequently. It produces as output not only a set of indexing frames for each document, but also conventional MeSH index terms, some of which are generated by inferencing rules encoded in the KB frames. Next, the various types of assistance provided by the system are presented and explained with examples. The report concludes by summarizing the research activities and accomplishments to date and plans for continued development of the system.},
 author = {Susanne M. Humphrey},
 doi = {10.1016/0306-4573(89)90092-7},
 journal = {Information Processing {\&}amp$\mathsemicolon$ Management},
 month = {jan},
 number = {1},
 pages = {73--88},
 publisher = {Elsevier {BV}},
 title = {{MedIndEx} system: medical indexing expert system},
 url = {https://doi.org/10.1016%2F0306-4573%2889%2990092-7},
 volume = {25},
 year = {1989}
}

@article{Iversen_2003,
 abstract = {This paper reports from a case study of an organization that implements a software metrics program to measure the effects of its improvement efforts. The program measures key indicators of all completed projects and summarizes progress information in a quarterly management report. The implementation turns out to be long and complex, as the organization is confronted with dilemmas based on contradictory demands and value conflicts. The process is interpreted as a combination of a rational engineering process in which a metrics program is constructed and put into use, and an evolutionary cultivation process in which basic values of the software organization are confronted and transformed. The analysis exemplifies the difficulties and challenges that software organizations face when bringing known principles for software metrics programs into practical use. The article discusses the insights gained from the case in six lessons that may be used by Software Process Improvement managers in implementing a successful metrics program.},
 author = {Jakob Iversen and Lars Mathiassen},
 doi = {10.1046/j.1365-2575.2003.00136.x},
 journal = {Information Systems Journal},
 month = {jan},
 number = {1},
 pages = {3--19},
 publisher = {Wiley},
 title = {Cultivation and engineering of a software metrics program},
 url = {https://doi.org/10.1046%2Fj.1365-2575.2003.00136.x},
 volume = {13},
 year = {2003}
}

@article{Kaiser_1982,
 abstract = {Information systems for large firms are typically designed by a team comprised of both users and systems personnel. The Management Information System (MIS) literature discusses a communication gap between the organization oriented users and the more technical systems staff. It is often hypothesized that systems personnel and users are different in terms of personality and behavior characteristics and that these differences are one of the primary reasons for the existence of a communication gap. This article summarizes a two-phased study. The first phase investigated personality characteristics of respondents from thirty-two large organizations who worked on design teams. The second phase examines, in detail, a system success and failure in one organization. Analysis was performed to see if there are significant differences on personality dimensions between users and systems personnel and to explore the relationship between these differences and system success. An operationalization of Jung's personality typology (Myers-Briggs Type indicator) was employed. The results show that the users involved in the systems design are very similar to their systems counterparts. Even more surprising is that the characteristics of these users are closer to the popular descriptions of systems staff than the analysts are. They also suggest that these similarities in personality types may have an impact on system success. The general implications of these findings in terms of the management of project teams and the MIS designs they create are discussed.},
 author = {Kate M. Kaiser and Robert P. Bostrom},
 doi = {10.2307/249066},
 journal = {{MIS} Quarterly},
 month = {dec},
 number = {4},
 pages = {43},
 publisher = {{JSTOR}},
 title = {Personality Characteristics of {MIS} Project Teams: An Empirical Study and Action-Research Design},
 url = {https://doi.org/10.2307%2F249066},
 volume = {6},
 year = {1982}
}

@article{Karlsson_2004,
 abstract = {The world of systems engineering methods is changing as rigorous ‘off-the-shelf’ methods gain popularity. The need for configuration of such methods is increasing accordingly. In this paper, method configuration is treated as a kind of method engineering, focusing on adaptation of a base method. A meta-method based on the concepts of Configuration Packages and Configuration Templates is proposed. Configuration Packages are pre-made reusable configurations of a base method suitable for a specific characteristic of a development situation. Configuration Templates with different characteristics can be related to different Configuration Packages and used as a base for reaching a situational method efficiently. The paper presents experiences from two empirical studies in which the Method for Method Configuration was developed and validated. These studies indicate that this meta-method eases the burden of the method engineer in configuring a method for particular project characteristics. Specifically it helped in deciding what in the base method to omit and to make sure that omissions made were congruent with the overall situational method.},
 author = {Fredrik Karlsson and Pär J {\AA}gerfalk},
 doi = {10.1016/j.infsof.2003.12.004},
 journal = {Information and Software Technology},
 month = {jul},
 number = {9},
 pages = {619--633},
 publisher = {Elsevier {BV}},
 title = {Method configuration: adapting to situational characteristics while creating reusable assets},
 url = {https://doi.org/10.1016%2Fj.infsof.2003.12.004},
 volume = {46},
 year = {2004}
}

@article{Klein_1999,
 abstract = {This article discusses the conduct and evaluation of interpretive research in information systems. While the conventions for evaluating information systems case studies conducted according to the natural science model of social science are now widely accepted, this is not the case for interpre- tive field studies. A set of principles for the con- duct and evaluation of interpretive field research in information systems is proposed, along with their philosophical rationale. The usefulness of the principles is illustrated by evaluating three published interpretive field studies drawn from the IS research literature. The intention of the},
 author = {Heinz K. Klein and Michael D. Myers},
 doi = {10.2307/249410},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {67},
 publisher = {{JSTOR}},
 title = {A Set of Principles for Conducting and Evaluating Interpretive Field Studies in Information Systems},
 url = {https://doi.org/10.2307%2F249410},
 volume = {23},
 year = {1999}
}

@article{Knuth_1989,
 abstract = {This paper is a case study of program evolution. The author kept track of all changes made to TEX during a period of ten years, including the changes made when the original program was first debugged in 1978. The log book of these errors, numbering more than 850 items, appears as an appendix to this paper. The errors have been classified into fifteen categories for purposes of analysis, and some of the noteworthy bugs are discussed in detail. The history of the TEX project can teach valuable lessons about the preparation of highly portable software and the maintenance of programs that aspire to high standards of reliability.},
 author = {Donald E. Knuth},
 doi = {10.1002/spe.4380190702},
 journal = {Software: Practice and Experience},
 month = {jul},
 number = {7},
 pages = {607--685},
 publisher = {Wiley},
 title = {The errors of tex},
 url = {https://doi.org/10.1002%2Fspe.4380190702},
 volume = {19},
 year = {1989}
}

@article{Kock_2001,
 abstract = {This article has no abstract},
 author = {Ned Kock and Francis Lau},
 doi = {10.1108/itp.2001.16114aaa.001},
 journal = {Information Technology {\&}amp$\mathsemicolon$ People},
 month = {mar},
 number = {1},
 publisher = {Emerald},
 title = {Information systems action research: serving two demanding masters},
 url = {https://doi.org/10.1108%2Fitp.2001.16114aaa.001},
 volume = {14},
 year = {2001}
}

@article{Kozar_1989,
 abstract = {A general opinion is that systems personnel are unlikely adopters of new systems development methods. Thirty-five systems persons from eleven organizations who attended a seminar/workshop on a requirements defining method were surveyed three months after the seminar to determine whether they used the method and factors influencing usage. Factors about the potential adoptee, the current tasks assigned, and the organization and its existing methods were considered as predictors of usage. The study found adopters to be younger, to have spent less time in their organization and in systems work, not to have a current method that they would have to give up, to perceive themselves to be risk takers, and to be more optimistic about their ability to use the method and have it fit in their organization.},
 author = {Kenneth A. Kozar},
 doi = {10.1080/07421222.1989.11517840},
 journal = {Journal of Management Information Systems},
 month = {mar},
 number = {4},
 pages = {73--86},
 publisher = {Informa {UK} Limited},
 title = {Adopting Systems Development Methods: An Exploratory Study},
 url = {https://doi.org/10.1080%2F07421222.1989.11517840},
 volume = {5},
 year = {1989}
}

@incollection{Lau_1997,
 abstract = {This paper examines the use of action research in information systems (IS) studies reported in literature over the last twenty-five years. Thirty such field studies and discussion papers on information technology, system design/use or socio-technical systems were reviewed and compared with those from social science. Evolving patterns are noted among these IS studies in terms of their underlying assumptions, study designs and presentation styles. A contemporary IS action research framework is proposed as a conceptual foundation and practical guide for researchers and practitioners interested in action research for IS studies. Its implications in IS research and practice are discussed.},
 author = {F. Lau},
 booktitle = {Information Systems and Qualitative Research},
 doi = {10.1007/978-0-387-35309-8_4},
 pages = {31--68},
 publisher = {Springer {US}},
 title = {A Review on the Use of Action Research in Information Systems Studies},
 url = {https://doi.org/10.1007%2F978-0-387-35309-8_4},
 year = {1997}
}

@article{Lee_1999,
 abstract = {According to Davenport and Markus IS research should emulate research in medicine and law. Inquiry in the natural sciences pursues the goal of truth in formal propositions, inquiry in the professions pursues the goal of effectiveness in actions. Research that systematizes and makes explicit what practitioners are already doing can be relevant by helkping to promote the dissemination of successful practices. Whereas IS researchers should not only call for relevance in IS research but also call for an empirically grounded and regourous understanding of relevance.},
 author = {Allen S. Lee},
 doi = {10.2307/249407},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {29},
 publisher = {{JSTOR}},
 title = {Rigor and Relevance in {MIS} Research: Beyond the Approach of Positivism Alone},
 url = {https://doi.org/10.2307%2F249407},
 volume = {23},
 year = {1999}
}

@article{Lyytinen_1999,
 abstract = {The various qualities that IS reasearch should have are discussed. The relevance of practice is not only about how a researcher learns to pay attention to thre areas of interest to practitioners and to communicate their findings, but also about what the researcher sees as practice and what elements are relevant in understanding and changing this practice. Megapackages (SAP), component-based architectures, and approaches to IS stategy and design are some of the innovations that can be traced to IS academics. A look at the related fields like computer-supported cooperative work research shows that many of the practices-like a reliance on ethnomethodology are diriven by theory-based research.},
 author = {Kalle Lyytinen},
 doi = {10.2307/249406},
 journal = {{MIS} Quarterly},
 month = {mar},
 number = {1},
 pages = {25},
 publisher = {{JSTOR}},
 title = {Empirical Research in Information Systems: On the Relevance of Practice in Thinking of {IS} Research},
 url = {https://doi.org/10.2307%2F249406},
 volume = {23},
 year = {1999}
}

@article{Madabhushi_1993,
 abstract = {The development of information systems (IS) emerges from the need for more expressive designs that could work well in diverse situations. Over the years, several methodologies have been proposed that offer tangible alternatives that capture solutions to the problems in context, and to a limited degree for those that could potentially occur in time. This paper describes the advantages and pitfalls within each of the known approaches and the reasons why no single methodology has gained general acceptance. Efforts to integrate these approaches often requires one to determine the right mix of features (Lyytinen, 1987). A case study of a large manufacturing organization from the midwest is presented and a new methodology that attempts to blend in pertinent features of the existing models of IS design is proposed.},
 author = {S.V.R. Madabhushi and Mary C. Jones and R. Leon Price},
 doi = {10.4018/irmj.1993010103},
 journal = {Information Resources Management Journal},
 month = {jan},
 number = {1},
 pages = {26--39},
 publisher = {{IGI} Global},
 title = {Systems Analysis and Design Models Revisited},
 url = {https://doi.org/10.4018%2Firmj.1993010103},
 volume = {6},
 year = {1993}
}

@article{Margaret_1994,
 abstract = {},
 author = {Tan Margaret},
 doi = {10.1080/07421222.1994.11518024},
 journal = {Journal of Management Information Systems},
 month = {mar},
 number = {4},
 pages = {159--182},
 publisher = {Informa {UK} Limited},
 title = {Establishing Mutual Understanding in Systems Design: An Empirical Study},
 url = {https://doi.org/10.1080%2F07421222.1994.11518024},
 volume = {10},
 year = {1994}
}

@article{Markus_1983,
 abstract = {Theories of resistance to management information systems (MIS) are important because they guide the implementation strategies and tactics chosen by implementors. Three basic theories of the causes of resistance underlie many prescriptions and rules for MIS implementation. Simply stated, people resist MIS because of their own internal factors, because of poor system design, and because of the interaction of specific system design features with aspects of the organizational context of system use. These theories differ in their basic assumptions about systems, organizations, and resistance; they also differ in predictions that can be derived from them and in their implications for the implementation process. These differences are described and the task of evaluating the theories on the bases of the differences is begun. Data from a case study are used to illustrate the theories and to demonstrate the superiority, for implementors, of the interaction theory.},
 author = {M. Lynne Markus},
 doi = {10.1145/358141.358148},
 journal = {Communications of the {ACM}},
 month = {jun},
 number = {6},
 pages = {430--444},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Power, politics, and {MIS} implementation},
 url = {https://doi.org/10.1145%2F358141.358148},
 volume = {26},
 year = {1983}
}

@techreport{McFeeley_1996,
 abstract = {},
 author = {Bob McFeeley},
 doi = {10.21236/ada305472},
 month = {feb},
 publisher = {Defense Technical Information Center},
 title = {{IDEAL}: A User{\textquotesingle}s Guide for Software Process Improvement.},
 url = {https://doi.org/10.21236%2Fada305472},
 year = {1996}
}

@article{McKay_2001,
 abstract = {Keywords Information systems, Research, Methodology, Action research

Abstract 

Action research (AR) is not without its critics, and those who reject some of the
paradigmatic assumptions embodied in AR maintain that AR is little more than consultancy,
that it is impossible to establish causal relationships, that it is difficult to generalize from AR
studies, that there is a risk of researcher bias, and that generally speaking, it lacks some of the
key qualities that are normally associated with rigorous research. The authors are sensitive to
such criticisms, for although they are committed action researchers, they have elsewhere
voiced their concerns about the quality of AR practice in the field of information systems. The
authors argue that part of the issue concerns the way in which we currently conceptualize AR.
In this article, the argument for a deeper and more reflective analysis of the meaning and full
implications of AR is developed, culminating in a model of AR being developed that explicitly
includes both a problem solving interest cycle and a research interest cycle. Important
implications of this new model are articulated, with examples to illustrate these points being
drawn from a real-life AR study.},
 author = {Judy McKay and Peter Marshall},
 doi = {10.1108/09593840110384771},
 journal = {Information Technology {\&}amp$\mathsemicolon$ People},
 month = {mar},
 number = {1},
 pages = {46--59},
 publisher = {Emerald},
 title = {The dual imperatives of action research},
 url = {https://doi.org/10.1108%2F09593840110384771},
 volume = {14},
 year = {2001}
}

@article{McKeen_1983,
 abstract = {In a field study of thirty-two business application systems, the relationship between the time spent in various phases of the development life cycle and the outcome of the development was examined. Results indicate that systems which spent more time in the analysis phase required less time to code, resulted in greater user satisfaction, and were developed in agreement with established budgets and deadlines. These results suggest preferred strategies for the development of application systems and have implications for their successful management and control.},
 author = {James D. McKeen},
 doi = {10.2307/249056},
 journal = {{MIS} Quarterly},
 month = {sep},
 number = {3},
 pages = {47},
 publisher = {{JSTOR}},
 title = {Successful Development Strategies for Business Application Systems},
 url = {https://doi.org/10.2307%2F249056},
 volume = {7},
 year = {1983}
}

@article{Mingers_2001,
 abstract = {his paper puts forward arguments in favor of a pluralist approach to IS research. Rather than advocating a single paradigm, be it interpretive or positivist, or even a plurality of paradigms within the discipline as a whole, it suggests that research results will be richer and more reliable if different research methods, preferably from different (existing) paradigms, are routinely combined together. The paper is organized into three sections after the Introduction. In §2, the main arguments for the desirability of multimethod research are put forward, while §3 discusses its feasibility in theory and practice. §4 outlines two frameworks that are helpful in designing mixed-method research studies. These are illustrated with a critical evaluation of three examples of empirical research. (Critical Pluralism; IS Research Methods; Methodology; Multimethodology; Paradigm; Qualitative Re- search; Critical Realism)},
 author = {John Mingers},
 doi = {10.1287/isre.12.3.240.9709},
 journal = {Information Systems Research},
 month = {sep},
 number = {3},
 pages = {240--259},
 publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
 title = {Combining {IS} Research Methods: Towards a Pluralist Methodology},
 url = {https://doi.org/10.1287%2Fisre.12.3.240.9709},
 volume = {12},
 year = {2001}
}

@article{Myers_1997,
 abstract = {Qualitative research involves the use of qualitative data, such as interviews, documents, and participant observation, to understand and explain social phenomena As the focus of information systems research shifts from technological to managerial and organizational issues, qualitative research methods become increasingly useful. This example of ''living scholarship'' within MISQ Discovery's worldwide web archive prov,des an overview of qualitative research for the newcomer and a set of resources for those more experienced. The work discusses philosophical perspectives that can inform qualitative research, qualitative research methods, techniques, and modes of analysis. Links to citation lists, Internet resources, software tools, and calls for papers are also included.},
 author = {Michael D. Myers},
 doi = {10.2307/249422},
 journal = {{MIS} Quarterly},
 month = {jun},
 number = {2},
 pages = {241},
 publisher = {{JSTOR}},
 title = {Qualitative Research in Information Systems},
 url = {https://doi.org/10.2307%2F249422},
 volume = {21},
 year = {1997}
}

@article{Necco_1987,
 abstract = {The process to develop computer-based information systems has changed significantly within the last ten years. Research was conducted to determine how organizations currently perform systems analysis and design. Responding organizations provided evaluations of their current approaches and tools. The results should provide insights for information systems practitioners and have implications for educational efforts and research in the information systems field.},
 author = {Charles R. Necco and Carl L. Gordon and Nancy W. Tsai},
 doi = {10.2307/248975},
 journal = {{MIS} Quarterly},
 month = {dec},
 number = {4},
 pages = {461},
 publisher = {{JSTOR}},
 title = {Systems Analysis and Design: Current Practices},
 url = {https://doi.org/10.2307%2F248975},
 volume = {11},
 year = {1987}
}

@article{Nonaka_1994,
 abstract = {This essay examines elements of a theory of organizational knowledge creation. To this end, a model for the management of the dynamic aspects of organizational knowledge is offered, using hands-on research and practical experience of Japanese firms. Two dimensions are examined to assess the importance of knowledge management: tacit and explicit knowledge. Four modes of knowledge creation through the interaction of tacit and explicit knowledge are presented: 1) socialization; 2) externalization; 3) internalization; and 4) combination. The process of organizational knowledge creation is also described in a corporate organizational setting. The model helps to explain how the knowledge of individuals, organizations, and societies can be enriched through the amplification of tacit and explicit knowledge of each. The key to this process is a joint creation of knowledge by both individuals and organizations. Organizations play an important role in mobilizing the tacit knowledge that individuals possess, as well as providing forums for knowledge creation through socialization, combination, externalization, and internalization. The concept of organizational knowledge creation allows for the development of a perspective that reaches beyond straightforward notions of organizational learning. Practical proposals, such as hypertext and middle-up-down management, are offered as modes of implementing more effective knowledge creation. (CBS)},
 author = {Ikujiro Nonaka},
 doi = {10.1287/orsc.5.1.14},
 journal = {Organization Science},
 month = {feb},
 number = {1},
 pages = {14--37},
 publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
 title = {A Dynamic Theory of Organizational Knowledge Creation},
 url = {https://doi.org/10.1287%2Forsc.5.1.14},
 volume = {5},
 year = {1994}
}

@article{Nygaard_1975,
 abstract = {The Norwegian National Union of Iron and Metal Workers (in this report abbreviated to MWU), the largest trade union in Norway, has recently completed a research project on ‘Planning Methods for the Trade Unions’. This is the first major research project in Norway conducted by a trade union without the employers participating. Joint projects have been going on for some time and are well publicized.},
 author = {Kristen Nygaard and Olav Terje Bergo},
 doi = {10.1108/eb055278},
 journal = {Personnel Review},
 month = {feb},
 number = {2},
 pages = {5--10},
 publisher = {Emerald},
 title = {The Trade Unions - New users of research},
 url = {https://doi.org/10.1108%2Feb055278},
 volume = {4},
 year = {1975}
}

@incollection{O_Regan_2002,
 abstract = {The Capability Maturity Model (CMM©) is a process maturity model which enables an organization to define and evolve its software processes. It is a premise in software engineering that there is a close relationship between the quality of the delivered software product and the quality and maturity of the underlying software processes. Consequently, it is important for a software organization to devote attention to the software processes as well as to the product. The CMM is a framework by which an organization may mature its software processes. It has been influenced by the ideas of some of the leading figures in the quality movement, such as Crosby, Deming, and Juran, etc.},
 author = {Gerard O'Regan},
 booktitle = {A Practical Approach to Software Quality},
 doi = {10.1007/978-0-387-22454-1_4},
 pages = {129--167},
 publisher = {Springer New York},
 title = {The Capability Maturity Model},
 url = {https://doi.org/10.1007%2F978-0-387-22454-1_4},
 year = {2002}
}

@techreport{Paulk_1993,
 abstract = {},
 author = {Mark C. Paulk and Bill Curtis and Mary B. Chrissis and Charles V. Weber},
 doi = {10.21236/ada263403},
 month = {feb},
 publisher = {Defense Technical Information Center},
 title = {Capability Maturity Model for Software, Version 1.1},
 url = {https://doi.org/10.21236%2Fada263403},
 year = {1993}
}

@article{Pettigrew_1990,
 abstract = {This paper reveals the author's theory of method for conducting longitudinal field research on change. The paper also discusses a range of practical problems in carrying out time-series research in organisational settings. The practical problems include dealing with time in longitudinal research; issues of site selection, choices about data collection and degrees of involvement the importance of clarifying research outputs. audience and presentation; and finally handling problems of complexity and simplicity associated with longitudinal comparative case study research on change. The paper concludes by discussing some ethical issues of longitudinal research field research, and managing a community of researchers.},
 author = {Andrew M. Pettigrew},
 doi = {10.1287/orsc.1.3.267},
 journal = {Organization Science},
 month = {aug},
 number = {3},
 pages = {267--292},
 publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
 title = {Longitudinal Field Research on Change: Theory and Practice},
 url = {https://doi.org/10.1287%2Forsc.1.3.267},
 volume = {1},
 year = {1990}
}

@article{Rapoport_1970,
 abstract = {},
 author = {Robert N. Rapoport},
 doi = {10.1177/001872677002300601},
 journal = {Human Relations},
 month = {dec},
 number = {6},
 pages = {499--513},
 publisher = {{SAGE} Publications},
 title = {Three Dilemmas in Action Research},
 url = {https://doi.org/10.1177%2F001872677002300601},
 volume = {23},
 year = {1970}
}

@article{Salaway_1987,
 abstract = {Information generated from communications between uses and analysts forms the basis for information systems development and is therefore a major determinant of success. This research investigates the effectiveness of these user/analyst interactions. Tape recordings of user/analyst communications during systems development are used to analyze traditional interaction methods. An alternative "organizational learning" interation methodology is developed based on the Argyris and Schon organizational learning theory. Finally, this new methodology is used by a group of professionals involved in systems projects and again evaluated based on tape recordings of their user/analyst communications. Results show that traditional user/analyst interactions display primarily error-prone characteristics, and that the new interaction methodology successfully generated more valid information with increased detection of errors.},
 author = {Gail Salaway},
 doi = {10.2307/249370},
 journal = {{MIS} Quarterly},
 month = {jun},
 number = {2},
 pages = {245},
 publisher = {{JSTOR}},
 title = {An Organizational Learning Approach to Information Systems Development},
 url = {https://doi.org/10.2307%2F249370},
 volume = {11},
 year = {1987}
}

@article{Schon_1986,
 abstract = {Contents: Professional Knowledge and Reflection-in-Action: The crisis of confidence in professional knowledge From technical rationality to reflection-in-action. Professional Contexts for Reflection-in-Action: Design as a reflective conversation with the situation Psychotherapy: The patient as a universe of one The structure of reflection-in-action Reflective practice in the science-based professions Town planning: Limits to reflection-in-action The art of managing: Reflection-in-action within an organizational learning system Patterns and limits of reflection-in-action across the professions. Conclusion: Implications for the professions and their place in society.},
 author = {Donald A. Schon and Vincent DeSanctis},
 doi = {10.1080/07377366.1986.10401080},
 journal = {The Journal of Continuing Higher Education},
 month = {jul},
 number = {3},
 pages = {29--30},
 publisher = {Informa {UK} Limited},
 title = {The Reflective Practitioner: How Professionals Think in Action},
 url = {https://doi.org/10.1080%2F07377366.1986.10401080},
 volume = {34},
 year = {1986}
}

@article{Tierney_1986,
 abstract = {Sumario: What culture is and does -- The dimensions of culture -- How to study and interpret culture -- The role leadership in building culture -- The evolution of culture and leadership -- Learning cultures and learning leaders},
 author = {William G. Tierney and Edgar H. Schein},
 doi = {10.2307/258322},
 journal = {The Academy of Management Review},
 month = {jul},
 number = {3},
 pages = {677},
 publisher = {Academy of Management},
 title = {Organizational Culture and Leadership},
 url = {https://doi.org/10.2307%2F258322},
 volume = {11},
 year = {1986}
}

@article{Vidgen_1997,
 abstract = {This paper describes the application of stakeholder analysis and soft systems thinking for an investigation of information system requirements. It is argued that it is appropriate to approach IS development as an exercise in managing complexity (soft systems) and pluralism (stakeholder analysis). A framework for investigating IS requirements is proposed that contrasts the current situation with the future situation and the real world with conceptual thinking about the real world. These aspects are viewed as outcomes of the process of IS requirements analysis, for which the metaphor of mediation is adopted in preference to presenting requirements analysis as a binary distinction between social construction and objectivity. The IS requirements analysis framework is applied in action research and the findings and learning that arose are presented.},
 author = {Richard Vidgen},
 doi = {10.1046/j.1365-2575.1997.00003.x},
 journal = {Information Systems Journal},
 month = {jan},
 number = {1},
 pages = {21--46},
 publisher = {Wiley},
 title = {Stakeholders, soft systems and technology: separation and mediation in the analysis of information system requirements},
 url = {https://doi.org/10.1046%2Fj.1365-2575.1997.00003.x},
 volume = {7},
 year = {1997}
}

@incollection{Vidgen_1997,
 abstract = {Understanding how technical artefacts are created and used within organizations is a central aspect of the IS research discipline. The conduct of research in an organizational setting is thus a major issue for the IS community. A research framework for in-context IS research is presented and used to position purified and hybrid forms of research method. From the framework, theoretical support for an action case research method is presented. The research framework is then used to describe and explain an IS research project from which a practice-based rationale for an action case method is argued. Characteristics of the action case method, a hybrid of interpretation and intervention, are described. Learning at three levels of analysis — concrete, general, and meta — is proposed as a way of reflecting on both the content of an IS research project and the IS research methods employed.},
 author = {R. Vidgen and K Braa},
 booktitle = {Information Systems and Qualitative Research},
 doi = {10.1007/978-0-387-35309-8_26},
 pages = {524--541},
 publisher = {Springer {US}},
 title = {Balancing Interpretation and Intervention in Information System Research: The Action Case Approach},
 url = {https://doi.org/10.1007%2F978-0-387-35309-8_26},
 year = {1997}
}

@article{Vitalari_1983,
 abstract = {The results of an empirical study comparing the thought processes of high- and low-rated systems analysts is presented. The report discusses the types of problem solving behaviors exhibited by the two groups of systems analysts and draws conclusions about the relationship of those behaviors to successful performance. The results suggest that qualitative differences exist in the problem solving methods of the two groups, and that the skills associated with high-rated problem solving may lead to better job performance and may be transferred to other practitioners. The article concludes with a set of recommendations for practioners, managers, and researchers concerned with problem solving and systems analysis.},
 author = {Nicholas P. Vitalari and Gary W. Dickson},
 doi = {10.1145/182.358458},
 journal = {Communications of the {ACM}},
 month = {nov},
 number = {11},
 pages = {948--956},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Problem solving for effective systems analysis},
 url = {https://doi.org/10.1145%2F182.358458},
 volume = {26},
 year = {1983}
}

@article{Vitalari_1985,
 abstract = {This study explores the content of the systems analyst's knowledge base. The study utilizes a protocol analysis methodology in a quasi-experimental research setting to define the types of knowledge used by 18 experienced systems analysts in solving an accounts receivable problem. The study provides preliminary findings regarding the core knowledge utilized by systems analysts, and differences in the knowledge utilized by high- and low-rated analysts.},
 author = {Nicholas P. Vitalari},
 doi = {10.2307/248950},
 journal = {{MIS} Quarterly},
 month = {sep},
 number = {3},
 pages = {221},
 publisher = {{JSTOR}},
 title = {Knowledge as a Basis for Expertise in Systems Analysis: An Empirical Study},
 url = {https://doi.org/10.2307%2F248950},
 volume = {9},
 year = {1985}
}

@article{Walz_1993,
 abstract = {More than half the cost of the development of complex computer-based information systems (IS) is attributable to decisions made in the upstream portion of the software development process; namely requirements specification and design. Knowledge acquisition, knowledge sharing, and knowledge integration are significant, time-consuming activities that precede the development of a design document. The purpose of this article is to examine how these activities unfolded over time inside an actual software design team. The findings reported in the paper challenge some of the conventional wisdom and common practices of managing software design teams.},
 author = {Diane B. Walz and Joyce J. Elam and Bill Curtis},
 doi = {10.1145/163430.163447},
 journal = {Communications of the {ACM}},
 month = {oct},
 number = {10},
 pages = {63--77},
 publisher = {Association for Computing Machinery ({ACM})},
 title = {Inside a software design team},
 url = {https://doi.org/10.1145%2F163430.163447},
 volume = {36},
 year = {1993}
}

@article{Webster_1993,
 abstract = {},
 author = {S Webster},
 doi = {10.1016/0950-5849(93)90013-s},
 journal = {Information and Software Technology},
 month = {jun},
 number = {6-7},
 pages = {420--422},
 publisher = {Elsevier {BV}},
 title = {Object-oriented analysis and design},
 url = {https://doi.org/10.1016%2F0950-5849%2893%2990013-s},
 volume = {35},
 year = {1993}
}

@article{White_1984,
 abstract = {A profusion of technology is insufficient to implement effective computer systems without the full utilization of human resources to develop such systems. The issue of fully developing and utilizing available human resources is currently receiving careful scrutiny in the MIS literature. One methodology for fully utilizing human resources has been maximizing productivity by stressing team effort. This research focuses on evaluating the systems development activities of two MIS project teams. Empirical evidence was gathered from interviews with MIS personnel and key users concerning strengths/weaknesses of the two project teams. Analysis was performed to determine the personality characteristics (as measured by the Myers-Briggs Type Indicator) of the MIS staff. The results of this analysis indicated a void of certain personality styles in project team one. This void correlated with weaknesses ascertained from the interview data for project team one. Project team two, with all four personality types represented, was evaluated as very successful. Recommendations are made for assembling project teams based on these findings.},
 author = {Kathy Brittain White},
 doi = {10.2307/249346},
 journal = {{MIS} Quarterly},
 month = {jun},
 number = {2},
 pages = {95},
 publisher = {{JSTOR}},
 title = {{MIS} Project Teams: An Investigation of Cognitive Style Implications},
 url = {https://doi.org/10.2307%2F249346},
 volume = {8},
 year = {1984}
}

@article{White_1986,
 abstract = {This research article reports on those factors project team members perceive as leading to systems development success. The amount of perceived impact of environmental variables, task variables and personal characteristics of project team members on systems success was explored. Results demonstrate that project team members are concerned with group process issues as well as with technical issues within the ranks of the project team. The sobering finding in their responses was that information systems personnel perceive neither management support nor user involvement as critical to the successful development of systems.},
 author = {Kathy Brittain White and Richard Leifer},
 doi = {10.2307/249253},
 journal = {{MIS} Quarterly},
 month = {sep},
 number = {3},
 pages = {215},
 publisher = {{JSTOR}},
 title = {Information Systems Development Success: Perspectives from Project Team Participants},
 url = {https://doi.org/10.2307%2F249253},
 volume = {10},
 year = {1986}
}

@article{1663532,
 abstract = {},
 author = {Brooks},
 doi = {10.1109/MC.1987.1663532},
 issn = {1558-0814},
 journal = {Computer},
 keywords = {},
 month = {April},
 number = {4},
 pages = {10-19},
 title = {No Silver Bullet Essence and Accidents of Software Engineering},
 volume = {20},
 year = {1987}
}

@article{1995,
 abstract = {},
 doi = {10.1016/0967-0661(95)90062-4},
 journal = {Control Engineering Practice},
 month = {dec},
 number = {12},
 pages = {1787--1788},
 publisher = {Elsevier {BV}},
 title = {A discipline for software engineering},
 url = {https://doi.org/10.1016%2F0967-0661%2895%2990062-4},
 volume = {3},
 year = {1995}
}

@article{1995,
 abstract = {},
 doi = {10.1016/0898-1221(95)90243-0},
 journal = {Computers {\&}amp$\mathsemicolon$ Mathematics with Applications},
 month = {nov},
 number = {9},
 pages = {126},
 publisher = {Elsevier {BV}},
 title = {A discipline for software engineering},
 url = {https://doi.org/10.1016%2F0898-1221%2895%2990243-0},
 volume = {30},
 year = {1995}
}

@article{391832,
 abstract = {Case studies help industry evaluate the benefits of methods and tools and provide a cost-effective way to ensure that process changes provide the desired results. However, unlike formal experiments and surveys, case studies do not have a well-understood theoretical basis. This article provides guidelines for organizing and analyzing case studies so that they produce meaningful results.<>},
 author = {Kitchenham, B. and Pickard, L. and Pfleeger, S.L.},
 doi = {10.1109/52.391832},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {July},
 number = {4},
 pages = {52-62},
 title = {Case studies for method and tool evaluation},
 volume = {12},
 year = {1995}
}

@inproceedings{592438,
 abstract = {This paper describes a final-year Master's course in large-scale software development. A number of issues such as closeness to an application domain and executing the software on a real target system are stressed in order to imitate an industrial environment. The experience gained from the course is discussed. In particular, effort data (in terms of man-hours) from the course are presented, both from the plan devised by the students, and the actual outcome. Furthermore, it is discussed how the data can be used to create an experience base for the future. The objective for next year's course is to let the students plan their projects based on the experience base. The experience base will also form the basis to complement the course with a complete experience factory.},
 author = {Wohlin, C.},
 booktitle = {Proceedings Tenth Conference on Software Engineering Education and Training},
 doi = {10.1109/SEDC.1997.592438},
 issn = {1093-0175},
 keywords = {},
 month = {April},
 number = {},
 pages = {40-52},
 title = {Meeting the challenge of large-scale software development in an educational environment},
 volume = {},
 year = {1997}
}

@inproceedings{592452,
 abstract = {In this experience report we present our recently introduced software engineering curriculum, which focuses on multi-semester, interlaced projects. Our curriculum aims at a very application-oriented education in order to bridge the gap between studentship and professional employeeship. We explain our structure of the curriculum and its support of real, external projects. Sample projects are discussed and our conclusions are presented showing how software engineering as a science and as a profession can benefit from teaching it by real-life projects. One interesting aspect might be the comparison of our Austrian (and European) situation and results with the situation in Canada and the U.S.A.},
 author = {Mayr, H.},
 booktitle = {Proceedings Tenth Conference on Software Engineering Education and Training},
 doi = {10.1109/SEDC.1997.592452},
 issn = {1093-0175},
 keywords = {},
 month = {April},
 number = {},
 pages = {176-184},
 title = {Teaching software engineering by means of a "virtual enterprise"},
 volume = {},
 year = {1997}
}

@inproceedings{592454,
 abstract = {Many computer science departments offer a course that features a software development project where students work as part of a team. An objective of this type of course is to simulate an industrial development environment thereby allowing students to experience some of the dynamics that they will encounter after completion of their study. The accuracy of the simulation can be improved, and hence the educational experienced enhanced, by the incorporation of industry participation directly into the course. Difficulties in organising and administering the project in the context of industry participation can occur in practice, which serve to deter the incorporation. This paper motivates industry participation in a team project course by identifying the potential benefits for the students, some of which are implicit, and also those for the industry sponsor, lecturer and host academic institution. A methodology for incorporating industry participation, which can be employed to overcome the difficulties in achieving these benefits, is presented. A model for administering a team project course in the context of industrial participation, which includes the use of an intranet as an enabling technology, is also described. The methodology and model, which have been employed successfully, can be utilised to improve the quality of the educational experience resulting from team project software development courses.},
 author = {Harrison, J.V.},
 booktitle = {Proceedings Tenth Conference on Software Engineering Education and Training},
 doi = {10.1109/SEDC.1997.592454},
 issn = {1093-0175},
 keywords = {},
 month = {April},
 number = {},
 pages = {192-203},
 title = {Enhancing software development project courses via industry participation},
 volume = {},
 year = {1997}
}

@inproceedings{592455,
 abstract = {A new software engineering educational model is proposed in order to more efficiently close the gap between industry software engineering needs and academic software engineering education. The model is analogous to the medical school/teaching hospital curriculum model; it is based on academic/industry collaboration using a "Software Center" as the implementation mechanism. The Software Center will provide experiential learning for students, research opportunities for faculty, and cost effective software solutions for industry. The Center was established in the Computer Science Department of Embry-Riddle University, Daytona Beach, Florida in Spring, 1996, the first industrial project is underway. This paper elaborates on the new curriculum model, past experiences with the model and the first industrial project. The project is described in terms of its goals, industry partnership, team organization, procedures and standards and project deliverables.},
 author = {Kornecki, A.J. and Hirmanpour, I. and Towhidnajad, M. and Boyd, R. and Ghiorzi, T. and Margolis, L.},
 booktitle = {Proceedings Tenth Conference on Software Engineering Education and Training},
 doi = {10.1109/SEDC.1997.592455},
 issn = {1093-0175},
 keywords = {},
 month = {April},
 number = {},
 pages = {204-211},
 title = {Strengthening software engineering education through academic industry collaboration},
 volume = {},
 year = {1997}
}

@article{60586,
 abstract = {Although software engineering is not yet a true engineering discipline, it has the potential to become one. Older engineering fields are examined to ascertain the character that software engineering might have. The current state of software technology is discussed, covering information processing as an economic force, the growing role of software in critical applications, the maturity of development techniques, and the scientific basis for software engineering practice. Five basic steps that the software engineering profession must take to become a true engineering discipline are described. They are: understanding the nature of expertise, recognizing different ways to get information, encouraging routine practice, expecting professional specializations, and improving the coupling between science and commercial practice.<>},
 author = {Shaw, M.},
 doi = {10.1109/52.60586},
 issn = {1937-4194},
 journal = {IEEE Software},
 keywords = {},
 month = {Nov},
 number = {6},
 pages = {15-24},
 title = {Prospects for an engineering discipline of software},
 volume = {7},
 year = {1990}
}

@book{Wohlin_2000,
 abstract = {},
 author = {Claes Wohlin and Per Runeson and Martin Höst and Magnus C. Ohlsson and Björn Regnell and Anders Wessl{\'{e}}n},
 doi = {10.1007/978-1-4615-4625-2},
 publisher = {Springer {US}},
 title = {Experimentation in Software Engineering},
 url = {https://doi.org/10.1007%2F978-1-4615-4625-2},
 year = {2000}
}

@inproceedings{Begel_2014,
 abstract = {In this paper, we present the results from two surveys related to data science applied to software engineering. The first survey solicited questions that software engineers would like data scientists to investigate about software, about software processes and practices, and about software engineers. Our analyses resulted in a list of 145 questions grouped into 12 categories. The second survey asked a different pool of software engineers to rate these 145 questions and identify the most important ones to work on first. Respondents favored questions that focus on how customers typically use their applications. We also saw opposition to questions that assess the performance of individual employees or compare them with one another. Our categorization and catalog of 145 questions can help researchers, practitioners, and educators to more easily focus their efforts on topics that are important to the software industry.},
 author = {Andrew Begel and Thomas Zimmermann},
 booktitle = {Proceedings of the 36th International Conference on Software Engineering},
 doi = {10.1145/2568225.2568233},
 month = {may},
 publisher = {{ACM}},
 title = {Analyze this! 145 questions for data scientists in software engineering},
 url = {https://doi.org/10.1145%2F2568225.2568233},
 year = {2014}
}

@inproceedings{Dieste_2013,
 abstract = {Background: There is no specialized survey of experiments conducted in the software industry. Goal: Identify the major features of software industry experiments, such as time distribution, independent and dependent variables, subject types, design types and challenges. Method: Systematic literature review, taking the form of a scoping study. Results: We have identified 10 experiments and five quasi-experiments up to July 2012. Most were run as of 2003. The main features of these studies are that they test technologies related to quality and management and analyse outcomes related to effectiveness and effort. Most experiments have a factorial design. The major challenges faced by experimenters are to minimize the cost of running the experiment for the company and to schedule the experiment so as not to interfere with production processes. Conclusion: Companies appear to be disinclined to run experiments because they are not perceived to have direct benefits. We believe that researchers staging a field experiment in a company should adopt a business-aligned stance and plan an experiment that clearly benefits managers and professionals.},
 author = {Oscar Dieste and Natalia Juristo and Mauro Danilo Martinez},
 booktitle = {2013 1st International Workshop on Conducting Empirical Studies in Industry ({CESI})},
 doi = {10.1109/cesi.2013.6618462},
 month = {may},
 publisher = {{IEEE}},
 title = {Software industry experiments: A systematic literature review},
 url = {https://doi.org/10.1109%2Fcesi.2013.6618462},
 year = {2013}
}

@inproceedings{Jedlitschka_2005,
 abstract = {One major problem for integrating study results into a common body of knowledge is the heterogeneity of reporting styles: (1) it is difficult to locate relevant information and (2) important information is often missing. Reporting guidelines are expected to support a systematic, standardized presentation of empirical research, thus improving reporting in order to support readers in (1) finding the information they are looking for, (2) understanding how an experiment is conducted, and (3) assessing the validity of its results. The objective of this paper is to survey the most prominent published proposals for reporting guidelines, and to derive a unified standard that which can serve as a starting point for further discussion. We provide detailed guidance on the expected content of the sections and subsections for reporting a specific type of empirical studies, i.e., controlled experiments. Before the guidelines can be evaluated, feedback from the research community is required. For this purpose, we propose to adapt guideline development processes from other disciplines.},
 author = {A. Jedlitschka and D. Pfahl},
 booktitle = {2005 International Symposium on Empirical Software Engineering, 2005.},
 doi = {10.1109/isese.2005.1541818},
 publisher = {{IEEE}},
 title = {Reporting guidelines for controlled experiments in software engineering},
 url = {https://doi.org/10.1109%2Fisese.2005.1541818},
 year = {2005}
}

@article{Kitchenham_2002,
 abstract = {Empirical software engineering research needs research guidelines to improve the research and reporting processes. We propose a preliminary set of research guidelines aimed at stimulating discussion among software researchers. They are based on a review of research guidelines developed for medical researchers and on our own experience in doing and reviewing software engineering research. The guidelines are intended to assist researchers, reviewers, and meta-analysts in designing, conducting, and evaluating empirical studies. Editorial boards of software engineering journals may wish to use our recommendations as a basis for developing guidelines for reviewers and for framing policies for dealing with the design, data collection, and analysis and reporting of empirical studies.},
 author = {B.A. Kitchenham and S.L. Pfleeger and L.M. Pickard and P.W. Jones and D.C. Hoaglin and K. El Emam and J. Rosenberg},
 doi = {10.1109/tse.2002.1027796},
 journal = {{IEEE} Transactions on Software Engineering},
 month = {aug},
 number = {8},
 pages = {721--734},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {Preliminary guidelines for empirical research in software engineering},
 url = {https://doi.org/10.1109%2Ftse.2002.1027796},
 volume = {28},
 year = {2002}
}

@article{Rafique_2013,
 abstract = {This paper provides a systematic meta-analysis of 27 studies that investigate the impact of Test-Driven Development (TDD) on external code quality and productivity. The results indicate that, in general, TDD has a small positive effect on quality but little to no discernible effect on productivity. However, subgroup analysis has found both the quality improvement and the productivity drop to be much larger in industrial studies in comparison with academic studies. A larger drop of productivity was found in studies where the difference in test effort between the TDD and the control group's process was significant. A larger improvement in quality was also found in the academic studies when the difference in test effort is substantial; however, no conclusion could be derived regarding the industrial studies due to the lack of data. Finally, the influence of developer experience and task size as moderator variables was investigated, and a statistically significant positive correlation was found between task size and the magnitude of the improvement in quality.},
 author = {Yahya Rafique and Vojislav B. Misic},
 doi = {10.1109/tse.2012.28},
 journal = {{IEEE} Transactions on Software Engineering},
 month = {jun},
 number = {6},
 pages = {835--856},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {The Effects of Test-Driven Development on External Quality and Productivity: A Meta-Analysis},
 url = {https://doi.org/10.1109%2Ftse.2012.28},
 volume = {39},
 year = {2013}
}

@article{Shull_2010,
 abstract = {What if someone argued that one of your basic conceptions about how to develop software was misguided? What would it take to change your mind? That's essentially the dilemma faced by advocates of test-driven development (TDD). The TDD paradigm argues that the basic cycle of developing code and then testing it to make sure it does what it's supposed to do-something drilled into most of us from the time we began learning software development- isn't the most effective approach. TDD replaces the traditional "code then test" cycle. First, you develop test cases for a small increment of functionality; then you write code that makes those tests run correctly. After each increment, you refactor the code to maintain code quality.},
 author = {Forrest Shull and Grigori Melnik and Burak Turhan and Lucas Layman and Madeline Diep and Hakan Erdogmus},
 doi = {10.1109/ms.2010.152},
 journal = {{IEEE} Software},
 month = {nov},
 number = {6},
 pages = {16--19},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {What Do We Know about Test-Driven Development?},
 url = {https://doi.org/10.1109%2Fms.2010.152},
 volume = {27},
 year = {2010}
}

@inproceedings{Sjoberg,
 abstract = {An important goal of most empirical software engineering research is the transfer of research results to industrial applications. Two important obstacles for this transfer are the lack of control of variables of case studies, i.e., the lack of explanatory power, and the lack of realism of controlled experiments. While it may be difficult to increase the explanatory power of case studies, there is a large potential for increasing the realism of controlled software engineering experiments. To convince industry about the validity and applicability of the experimental results, the tasks, subjects and the environments of the experiments should be as realistic as practically possible. Such experiments are, however, more expensive than experiments involving students, small tasks and pen-and-paper environments. Consequently, a change towards more realistic experiments requires a change in the amount of resources spent on software engineering experiments. This paper argues that software engineering researchers should apply for resources enabling expensive and realistic software engineering experiments similar to how other researchers apply for resources for expensive software and hardware that are necessary for their research. The paper describes experiences from recent experiments that varied in size from involving one software professional for 5 days to 130 software professionals, from 9 consultancy companies, for one day each.},
 author = {D.I.K. Sjoberg and B. Anda and E. Arisholm and T. Dyba and M. Jorgensen and A. Karahasanovic and E.F. Koren and M. Vokac},
 booktitle = {Proceedings International Symposium on Empirical Software Engineering},
 doi = {10.1109/isese.2002.1166921},
 publisher = {{IEEE} Comput. Soc},
 title = {Conducting realistic experiments in software engineering},
 url = {https://doi.org/10.1109%2Fisese.2002.1166921}
}

@inproceedings{Votta_1995,
 abstract = {What more should we be doing to better understand process? I
believe that we should observe professional software developers in their
organizations. We should study what they do, and then build productive
theories (a theory that addresses some important and significantly
defensible explanation for the phenomena) to explain why they are doing
what we observe. Finally, we should refine these theories by
demonstrating and confirming our hypotheses through sequences of
experiments},
 author = {L.G. Votta},
 booktitle = {Proceedings. Ninth International Software Process Workshop},
 doi = {10.1109/ispw.1994.512773},
 publisher = {{IEEE}},
 title = {By the way, has anyone studied any real programmers, yet? [software development process]},
 url = {https://doi.org/10.1109%2Fispw.1994.512773},
 year = {1995}
}

@book{Wohlin_2000,
 abstract = {},
 author = {Claes Wohlin and Per Runeson and Martin Höst and Magnus C. Ohlsson and Björn Regnell and Anders Wessl{\'{e}}n},
 doi = {10.1007/978-1-4615-4625-2},
 publisher = {Springer {US}},
 title = {Experimentation in Software Engineering},
 url = {https://doi.org/10.1007%2F978-1-4615-4625-2},
 year = {2000}
}

@inproceedings{Wohlin_2013,
 abstract = {Software engineering research can be done in many ways, in particular it can be done in different ways when it comes to working with industry. This paper presents a list of top 10 challenges to work with industry based on our experience from working with industry in a very close collaboration with continuous exchange of knowledge and information. The top 10 list is based on a large number of research projects and empirical studies conducted with industrial research partners since 1983. It is concluded that close collaboration is a long-term undertaking and a large investment. The importance of addressing the top 10 challenges is stressed, since they form the basis for a long-term sustainable and successful collaboration between industry and academia.},
 author = {Claes Wohlin},
 booktitle = {2013 1st International Workshop on Conducting Empirical Studies in Industry ({CESI})},
 doi = {10.1109/cesi.2013.6618469},
 month = {may},
 publisher = {{IEEE}},
 title = {Empirical software engineering research with industry: Top 10 challenges},
 url = {https://doi.org/10.1109%2Fcesi.2013.6618469},
 year = {2013}
}

@incollection{Zelkowitz_2003,
 abstract = {When to apply a new technology in an organization is a critical decision for every software development organization. Earlier work defines a set of methods that the research community uses when a new technology is developed. This chapter presents a discussion of the set of methods that industrial organizations use before adopting a new technology. First there is a brief definition of the earlier research methods and then a definition of the set of industrial methods. A comparison of the two sets leads into the perspectives of these methods of experts in the research and industrial community via surveys made to those communities.},
 author = {Marvin V. Zelkowitz and Dolores R. Wallace and David W. Binkley},
 booktitle = {Lecture Notes on Empirical Software Engineering},
 doi = {10.1142/9789812795588_0006},
 month = {mar},
 pages = {229--263},
 publisher = {{WORLD} {SCIENTIFIC}},
 title = {Experimental Validation of New Software Technology},
 url = {https://doi.org/10.1142%2F9789812795588_0006},
 year = {2003}
}

